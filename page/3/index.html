<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"eimadrigal.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Hello World">
<meta property="og:type" content="website">
<meta property="og:title" content="EI Madrigal&#39;s Space">
<meta property="og:url" content="https://eimadrigal.github.io/page/3/index.html">
<meta property="og:site_name" content="EI Madrigal&#39;s Space">
<meta property="og:description" content="Hello World">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="EIMadrigal">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://eimadrigal.github.io/page/3/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>EI Madrigal's Space</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">EI Madrigal's Space</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/06/03/Learn%20to%20Learn/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/03/Learn%20to%20Learn/" class="post-title-link" itemprop="url">Learn to Learn</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-06-03 10:20:00" itemprop="dateCreated datePublished" datetime="2021-06-03T10:20:00+08:00">2021-06-03</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>上了十几年学，依然不会学习。不知是因为中学一些糟糕习惯的延续，还是当代知识难度的加深，我总是感受到日常学习的辛苦：身体累、脑子累、心也累。</p>
<p>刻苦的确是一种很好的品质，但这种品质有些时候未免有些夸大其词了。傻傻地机械地重复在中学时代那种应试环境或许可以带来一些成绩的提升，但是显然已经不适应现在的我。我尝试将每天安排得满满当当，恨不得每一分每一秒都在学习，然而效果却并不如人意。</p>
<p>除了智力等一些先天因素外，我个人觉得有以下几点问题：</p>
<ol type="1">
<li>没有找到合适的学习方法，缺乏深度思考和知识体系。我总是试图单点单点地掌握未知的知识点，试图掌握每一处细节，甚至使用死记硬背的方式处理核心问题。笔记和博客也多是摘抄型，独立理解实现太少。</li>
<li>效率低下。尽管学习时长可能足够，但是且不说大多时间都在摸鱼，即使纯粹学习时间也经常犯困，无法专注完成手头的某项任务，总是过于频繁地切换。效率*时长=最终效果自然不会很好。</li>
<li>单打独斗。周围少有一起交流进步的伙伴，遇到问题只能单向地从互联网获取信息，没法通过讨论等形式取得快速进步。</li>
</ol>
<p>最近看了Marty Lobdell的一个演讲Study Less, Study Smart(<a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=IlU-zDU6aQ0">YouTube</a>/<a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1Pz4y1f7oi">B站</a>)，有些启发，但是如何学习这种事是绝没有普适准则的，只能结合自身实际摸索总结。Marty还写了一本同名的书，内容比演讲稍微细化一些。</p>
<p>Marty认为比较重要的有：</p>
<ol type="1">
<li>番茄工作法。每学习25~30min应该休息5min，可以听一首音乐、出去上个厕所、吃点喝点、回消息等等，这样再次回来后注意力和效率又会回升到一个较高的水平，而非效率指数级下降的持续长时间学习。完成一天的工作后，对自己进行更丰厚一些的奖励，比如看个电影、吃顿大餐等等，以形成正反馈。</li>
<li>寻找一个专门的学习地点，书桌是用来学习的，床是用来睡觉的。Intend to learn rather than incidental learn.</li>
<li>费曼学习法。看完材料后，深加工以后尝试用自己的话复述给别人听，能准确复述或者能把别人讲懂才行。</li>
<li>对于学习材料要SQ4R(Survey, Question, Read, Record, Recite, Review)，要主动理解思考自己的笔记，产生更加深刻的认识，而非机械地摘抄背诵。</li>
<li>高质量睡眠、高质量运动。</li>
</ol>
<p>结合自身缺点和学科特点，我认为可以有以下改进措施：</p>
<ol type="1">
<li>每学习一个新东西，理解算法流程、数学推导、实现细节等确实重要，但更重要的是领会方法的思想动机，掌握优缺点和应用场景，将其纳入知识体系中，也就是所谓的“解决现实问题的能力”。</li>
<li>合理安排学习计划，劳逸结合。不要安排得过于紧密，也不要过于松散。制定的目标不能模棱两可，要有可评估性，即某段时间里要扎扎实实做完TODO LIST上的某件事。</li>
<li>组队学习，提出自己的问题，解答别人的问题。</li>
<li>累了就休息，不要在低效率状态下学习工作。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/05/23/%E4%BA%BA%E7%94%9F%E6%B0%B8%E8%BF%9C%E8%89%B0%E9%9A%BE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/23/%E4%BA%BA%E7%94%9F%E6%B0%B8%E8%BF%9C%E8%89%B0%E9%9A%BE/" class="post-title-link" itemprop="url">人生永远艰难</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-05-23 16:16:00" itemprop="dateCreated datePublished" datetime="2021-05-23T16:16:00+08:00">2021-05-23</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>很抱歉在这样一个美好的日子用了这样一个忧伤的标题，有感于最近所闻所思，实在难以入眠，索性爬起来，聊作记录。</p>
<p>昨天新垣结衣宣布结婚，一大堆宅男苦嚎自己痛失老婆，我并非宅男，也不是新垣的粉丝，不过我的心情并不比那些粉丝们好到哪里去。</p>
<p>研一即将结束，回顾过去几个月的生活学习，很难谈得上满意。庆幸的是，其中的问题大概率并不是因为我。</p>
<p>不知道是现实的压力还是社会的风气，周围的人大部分好像都陷入了一种病态的狂热之中，每天聊天的话题永远都是发文章、奖学金、出去实习、如何毕业以及毕业后去哪上班。不光是实验室的人这样，好像所有人都这样，哪怕是曾经散发着耀眼的理想主义光芒的朋友也有被侵蚀到。以我所在的计算机实验室为例：你永远感受不到ta们对于计算机科学的发自内心的热爱，当然更加谈不上ta们有什么理想，有的只是无聊的功利心和对结果的病态渴求，因此你永远看不到ta们enjoy的过程，相反，这种追求会令人痛苦。</p>
<p>我压根不想理这帮人，仔细想想：我在这个地方基本没有朋友，当然我也不想结交这些所谓的朋友。</p>
<p>关于实验室和学校的环境，更是无数同学包括我在内的梦魇。学校和学院一方面声称要力破五唯，另一方面却更加变本加厉地用文章数目决定毕业规则，真是又当婊子又立牌坊。实验室的环境则更加不可思议，大老板王某是官宦之家，并且年纪轻轻就被聘请为正教授，当然他的学术水平还是很高的，发了一些顶尖的期刊，可是他对实验室的管理堪称灾难，并且我严重怀疑他精神受过一定程度刺激，或者先天性格古怪，这绝不是开玩笑。</p>
<p>典型的“笑面虎”，他对硕士生基本没有任何有效的指导，指派的课题也许压根没有经过慎重考虑，甚至在研二学长即将完成课题的情况下，组会上狠批其工作没有创新点，不足以满足要求，导致该学长只能临时更换课题。我进组这几个月以来，组里的博士生一个因为开题答辩不过退学，一个博三学姐彻底脱离了电信学部，转去了社会科学，一个研二学长开题不过转至其他组。目前选他课题的同门都痛不欲生，发微信不回，开组会除了一直问为什么、或者一直重复那些正确的废话以外传达不出任何有效的指导信息，总是哼哼哈哈应付了事。</p>
<p>组里目前有6个老师，除了王，还有张某，临近退休，很明显也是在混日子等死，并且对相关课题没有任何见解，名下的学生都只能选择其他老师的课题，这种奇葩除了对考勤工作格外关心、组会时怼怼学生，基本没有任何用处，不知道这种人才当年怎么评上教授的，这也从侧面反映了西交的裙带有多么严重，这些破事暂且不表。还有2个很年轻的助理教授，她们自己科研压力也很大，自然没时间指导我们。剩下的一个赖，一个朱，人品都十分堪忧，对学生也是极尽压榨。朱基本没有任何学术能力，可以说对机器学习一窍不通，也完全不会follow最新的科研进展，只会找学生要结果和抢学生的一作。最搞笑的就是：文章已经投出去了，她自己连文章里的算法都没懂，真不知道之前哪里来的勇气给我改论文...朱还总是喜欢让学生干些杂七杂八的事并且认为理所应当（建个qq群也要让学生来），并且会不时打小报告，背后捅你一刀哦（我自己就挨过几刀）~好像天底下只有她自己的事最重要，别人都应该为她服务。最可笑的是：这人总是把自己伪装成指路名师，但实际上她只关心自己的利益和前途（通过抢一作实现），学生的死活和去向她压根不会在乎，更别说给你推荐工作什么的。</p>
<p>组里目前还没有毕业的博士生，并且30个人做的方向可以说应有尽有，完全不搭嘎。王主要研究生信，张没有任何研究方向，赖研究统计，朱做自动机器学习，如此分散的方向导致极其缺乏学长学姐的帮带，所有的坑都要自己重新踩一遍。因此组里的成果并不稳定，加上王自己心思已经完全不在科研上，他甚至在组会上很自豪地说自己现在主要在终南山上研究茶艺，并且说自己代表作已经够了，大有功成名就的感觉。的确，这种情况下，学生基本可以忽略不计。</p>
<p>人生真是魔幻啊！你能主动控制的东西少之又少，当时找导师就想着避坑，谁曾想还是如此。我觉得现在唯一支撑着我的，就是我对CS的仅存的一丝丝喜爱，你知道，在这种教育环境下保留着这种喜爱是多么奢侈的一件事吗？再次感谢一些前辈的指点，感谢众多国外高校的公开课。我告诉自己每天都要有充电时间，晚上学一些自己感兴趣的东西。</p>
<p>理想主义者总是看起来有些幼稚，甚至有些悲凉。我性格里有反抗基因，讨厌规则的约束，也会用实际行动反对，但我清楚自己不是一个彻底的决绝的人，没法彻底逃离，但是底线是不要把自己搞得太卑微。</p>
<p>每个人都有自己的生活方式，不必艳羡别人，未来的npy至少要有些理想主义气质，否则我真的不知道该如何相处。偶尔会想，是我把自己搞得太复杂了吗，是我每天想太多东西吗？我觉得像别人那样简简单单生活也不错啊，每天聊聊考试，作业，科研，去哪吃饭。可是我真的不是这样子合群，我太独立，太散漫，太逆反，我希望别人和我一样，可是这怎么可能呢？周围没有一个人和我一样，我有些孤独。cyq带我快乐吧，一起幸福吧。</p>
<p>我的要求并不算很高：</p>
<ol type="1">
<li>一个志同道合的朋友，一起学习聊天啥的</li>
<li>顺利毕业</li>
<li>找个差不多的工作就行了，每天过得幸福快乐就好了</li>
</ol>
<p><strong>事已至此，我觉得被负面情绪笼罩没有什么，但是抱怨无法解决任何问题，而且会让人变得焦躁，我应该更多地专注于自己能做些什么，而不是像愤青一样整日咒骂</strong>。我觉得以后比较重要的几点是：</p>
<ol type="1">
<li>遇到问题，分析原因，冷静地尝试解决问题，尽量少地被外界环境影响；</li>
<li>静下心来，汲取知识。试着成为一个创新者，而不是成为一个抄袭者，积累找工作的资本；</li>
<li>要好好学习了呢，贼认真的那种。Code everyday by yourself！</li>
<li>永远不要压抑自己的感情，无论是热爱，喜悦，还是悲伤，迷惘；</li>
<li>晚上不要梦想些有的没的，最好还是反思下自己一天的生活，做点感恩的事；</li>
<li>学琴，学开车！</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/05/07/Dealing%20with%20Imbalanced%20Datasets/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/07/Dealing%20with%20Imbalanced%20Datasets/" class="post-title-link" itemprop="url">Dealing with Imbalanced Datasets</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-05-07 05:54:00" itemprop="dateCreated datePublished" datetime="2021-05-07T05:54:00+08:00">2021-05-07</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="motivation">Motivation</h2>
<p>The Imbalanced Datasets are very common in our life such as illegal users or illness check. The machine learning model always performs bad on these datasets if there are no specific dealings, especially the prediction accuracy of minority class. For example, if the data is highly imbalanced such as 9995(negative):5(positive), then if your model just let every instance to be negative and you can get an acc of 99.95% but the result is meaningless. Another example is that misclassifying the minority is very severe. Assume that you misclassify the patient as normal. Oh my god!</p>
<p>So researchers proposed two kinds of methods for this problem:</p>
<ul>
<li>Cost Sensitive Learning When <strong>training</strong> your model, it will give different classes different weights in the <strong>loss function</strong> thus let the model focus more on the minority class. In sklearn, there are <code>class_weight</code> and <code>sample_weight</code> for you. For <code>class_weight</code>, you can specify the weights for different classes such as <code>&#123;0:0.1,1:0.9&#125;</code> or you can set it to <code>balanced</code> then weights will be computed by <span class="math inline">\(\frac{\#samples}{\#classes\ *\ np.bincount(y)}\)</span>. For <code>fit(sample_weight=)</code>, you give <strong>every instance</strong> different weights. When computing the loss for the instance, it will be <code>class_weight</code> * <code>sample_weight</code> * <code>loss</code>.</li>
<li>Sampling Sampling means that we will change the original dataset rather than giving them different weights.</li>
</ul>
<h2 id="sampling-methods">Sampling Methods</h2>
<p>Over-sampling means to increment the minority class.</p>
<ul>
<li>Random Over Sampling To sample from minority class with replacement to let the number of each class is 1:1. Overfitting on minority class.</li>
<li>Synthetic Minority Oversampling Technique (SMOTE) <span class="math display">\[
x_{new}=x_i+\lambda(x_{zi}-x_i)
\]</span> First you find the <code>k_neighbors</code> of <span class="math inline">\(x_i\)</span> in the minority class, then just select one <span class="math inline">\(x_{zi}\)</span> randomly and produce the new one. There are some variants such as borderline SMOTE, SVM SMOTE and KMeans SMOTE.</li>
<li>Adaptive Synthetic (ADASYN) The difference between SMOTE and ADASYN is that SMOTE will generate new samples for random minority data until 1:1. But ADASYN will automatically decide the number of new points generated for each <span class="math inline">\(x_i\)</span>. There will be more points generated if there are more majority data around <span class="math inline">\(x_i\)</span>.</li>
</ul>
<p>Under-sampling means to decrease the majority class.</p>
<ul>
<li>RUS Data waste.</li>
<li></li>
</ul>
<h2 id="example">Example</h2>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/05/02/%E5%BD%BB%E5%BA%95%E4%BD%9C%E5%88%AB/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/05/02/%E5%BD%BB%E5%BA%95%E4%BD%9C%E5%88%AB/" class="post-title-link" itemprop="url">彻底作别</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-05-02 15:29:00" itemprop="dateCreated datePublished" datetime="2021-05-02T15:29:00+08:00">2021-05-02</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>还有2天我就23岁半了，趁着五一假期的闲暇，又翻了翻过去的相册，一时间百感交集，差点泪流满面：既怀念那段朦胧的时光，又对比着现在的窘境，伴着耳机里杰伦的歌，我觉得是时候做一个彻底的告别了，尽管这本该就是早早封存的记忆。</p>
<p>之前虽然说过已经开始了崭新的人生，但现在还是有些想念曾经的一些人、一些事，以至于晚上只能靠着这些记忆和憧憬去入睡，但醒来以后才深切感受到这些倚靠的无力和虚无。很多时候我觉得自己有些矛盾，甚至有抑郁和精神分裂的倾向：一方面我瞧不上现在的环境以及这个环境下的人，另一方面却还要戴着面具在这里生活。我觉得还是因为太过注重于过去的美妙，还是太沉迷于过去的优越，少年得志总归有些不利。</p>
<p>听着杰伦的歌，翻着过往的点滴，好像大哭一场，告别过去的岁月。有太多太多没敢去做的事，回想起来觉得当年好傻好青涩，如果勇敢一点，如果成熟一点，结果会不会不一样？如今真的长大了，忘记了太多，我变得封闭起来。 现在成熟了，懂事了，却再也没有当年的感觉了！我永远都是感性大于理性， 曾经的我，喜欢足球，喜欢装酷，喜欢所有运动，喜欢写一些虚无缥缈，华丽的词句，喜欢和别人比文采 就让这些过往永远尘封在过去吧，就像加密的相册和说说一样，平时不再触碰，待将来与人分享。我想每个人都有自己的故事，期望能听到分享，而不是庸俗。</p>
<p>过得很累的原因主要还是在于一直戴着面具生活，跟周围的人无法吐露心声，急切需要找到一个能说心里话的红颜知己，可是那个人究竟在哪呢？是清华的她吗？我不知道，真的不知道！！！</p>
<p>我还是一直在逃避，究竟在逃避什么，是因为自卑，还是因为自负？或者是社交恐惧？我说不太清楚，无论遇见男女朋友，我的第一反应就是躲避，而不是主动迎上去打招呼。我是多么希望有一天我爱的人也会恰好爱我。</p>
<p>首先，摆正自己的心态，不要觉得西交的女生都是土，还有就是自己的要求不要太高，自己也就普通人水平。 其次，对待周围的女生，不要装作没看见或者冷脸以待，笑脸相迎，多多聊天。 最后，眼光也不要局限于西交这块，初高中同学只要聊得来，都可以试试。</p>
<p>不知道此生还有没有人能够打开我心扉。</p>
<p>以后面对朋友，要多用当下和未来的视角，而非过多沉迷于美妙的梦境。</p>
<p>Fancy Dream, Poor Memory</p>
<p>最最重要的，还是要有面对的勇气，豁达面对过往烟云、认真面对当下人事，不念过往、不惧将来。剩下的就只能交给命运了</p>
<p>属于时间的就让它归于时间吧。希望以后的睡眠更多依赖于当下的小确幸而非无端的想象。祝你我安好，祝来日方长，祝有缘再见！</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/04/22/Kick%20Start%202013/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/22/Kick%20Start%202013/" class="post-title-link" itemprop="url">Kick Start 2013</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-22 01:33:00" itemprop="dateCreated datePublished" datetime="2021-04-22T01:33:00+08:00">2021-04-22</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="practice-round">Practice Round</h2>
<ol type="1">
<li>题目大意：给定一堆人名，从上向下扫描，一旦当前值比前一个的字典序小，就将当前值移动到正确的位置，不论移动多远，代价都是1，求代价总和。</li>
</ol>
<p>和插入排序类似，如果当前值<span class="math inline">\(j\)</span>比<span class="math inline">\(j-1\)</span>小，将<span class="math inline">\(j\)</span>移到前面合适的位置，此时前<span class="math inline">\(j\)</span>个数是局部有序的。这道题只要求出代价和即可，不需要输出排序后的结果，不需要真正去移动，只要记录前<span class="math inline">\(j\)</span>个的最大值，如果<span class="math inline">\(j+1\)</span>比最大值小，那么必然触发一次移动。举例： 2 1 5 3 0 j=1, max=2, cost++ 1 2 5 3 0 j=3, max=5, cost++ 1 2 3 5 0 j=0, max=5, cost++ 0 1 2 3 5 有2个地方要注意：<code>cin</code>读入<code>string</code>时，会把空格/回车作为分隔符，遇到即停止，所以要用<code>getline()</code>，默认以回车结束；<code>cin</code>读完<code>int</code>后，换行符<code>\n</code>仍然在输入流里，所以下一次的<code>getline</code>会先读<code>\n</code>，故用<code>cin.get()</code>先取走<code>\n</code>。</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">int</span> argc, <span class="keyword">char</span>** argv)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">int</span> T, N;</span><br><span class="line">    cin &gt;&gt; T;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; T; ++i) &#123;</span><br><span class="line">        cin &gt;&gt; N;</span><br><span class="line">        cin.<span class="built_in">get</span>();</span><br><span class="line">        <span class="function">vector&lt;string&gt; <span class="title">names</span><span class="params">(N)</span></span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; N; ++j) &#123;</span><br><span class="line">            <span class="built_in">getline</span>(cin, names[j]);</span><br><span class="line">        &#125;</span><br><span class="line">        </span><br><span class="line">        string curMax;</span><br><span class="line">        <span class="keyword">int</span> money = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> j = <span class="number">0</span>; j &lt; N; ++j) &#123;</span><br><span class="line">            <span class="keyword">if</span> (j == <span class="number">0</span>) &#123;</span><br><span class="line">                curMax = names[<span class="number">0</span>];</span><br><span class="line">                <span class="keyword">continue</span>;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (names[j].<span class="built_in">compare</span>(curMax) &lt; <span class="number">0</span>) &#123;</span><br><span class="line">                ++money;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">else</span> &#123;</span><br><span class="line">                curMax = names[j];</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        cout &lt;&lt; <span class="string">&quot;Case #&quot;</span> &lt;&lt; i + <span class="number">1</span> &lt;&lt; <span class="string">&quot;: &quot;</span> &lt;&lt; money &lt;&lt; endl;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<ol start="2" type="1">
<li>题目大意：</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/04/13/Monte-Carlo%20Tree%20Search/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/13/Monte-Carlo%20Tree%20Search/" class="post-title-link" itemprop="url">Monte-Carlo Tree Search</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-13 11:53:00" itemprop="dateCreated datePublished" datetime="2021-04-13T11:53:00+08:00">2021-04-13</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="motivation">Motivation</h2>
<p>We all know that Monte Carlo Simulation is used to estimate some unknown variables through random simulation. It is because that the process is too complicated so we cannot know the true rule behind it. Only god knows. But thankful to the randomness we can do lots of experiments to approach the truth.</p>
<p>MCTS has the same idea but it is based on a tree. Every path from root to leaf forms a solution and the whole tree defines the search space. It is a heuristic search strategy based on some loss functions. But it will follow not only the loss but also try to explore the unvisited nodes. So it's also trying to make a balance between exploration &amp; exploitation.</p>
<p>One iteration has 4 processes: Selection, Expansion, Simulation and Backpropagation. Let's start to build the tree. Initially the tree only has a root node. Every node holds 3 info: action list for the next decision; visit times to measure the exploration; quality values to measure the exploitation.</p>
<ol type="1">
<li>Selection Using some criterion to select a child node which is eager to expand. There are 3 possibilities for the current state: If all the actions have been expanded thus the node has finished a complete search, then we will find a child with max UCB value and go down the tree recursively; Else if there are still some actions which have not been expanded (e.g. the node has 20 possible actions but there are 19 child node in the tree), then it will select one action randomly from the unexpanded actions and do Step 2 Expansion; Else game over and do Step 4 Backpropagation.</li>
<li>Expansion We have found the most eager node N to expand and the action A after Selection. So we need to add a new node S to the tree as N's child node by doing A.</li>
<li>Simulation/Playout Start from S to let the game run randomly until game over. Then we get a performance to be S's initial quality value.</li>
<li>Backpropagation The nodes along the path from root to N will update their quality values after S's simulation.</li>
</ol>
<p>After some fixed number of iterations or time limit, we will get a large tree and select the best leaf node as the result. Below is a figure: <img src="https://img-blog.csdnimg.cn/20210404201349819.png" alt="在这里插入图片描述" /> ## Upper Confidence Bound (UCB) When we need to select a child node to go down the tree, we usually use UCB criterion: <span class="math display">\[\underset{child}{\operatorname{arg\ max}}(\hat\mu_{child}+C\sqrt\frac{log\ n(s)}{n(child)})\]</span> <span class="math inline">\(\hat\mu_{child}\)</span> is the average reward gathered over all tree-walks with prefix child, <span class="math inline">\(n(s)\)</span> the number of the parent's visits and <span class="math inline">\(C\)</span> is constant controlling exploration &amp; exploitation. UCB tends to select a node with high quality value (for exploitation) and relatively low visit times (for exploration). ## An example 1. Initial tree Actually we only have root node <span class="math inline">\(S_0\)</span>. Assume there are only two actions <span class="math inline">\(A_1\)</span> and <span class="math inline">\(A_2\)</span>. <span class="math inline">\((Q,N)\)</span> means the quality value and #visits of this node. <img src="https://img-blog.csdnimg.cn/20210519201721793.png" alt="在这里插入图片描述" /> 2. First Iteration Since <span class="math inline">\(S_0\)</span> is a leaf node now, we should expand. Since the 2 actions are both unexpanded so we randomly select one (assume we select <span class="math inline">\(A_1\)</span>). Then we add <span class="math inline">\(S_1\)</span> to the tree and playout from <span class="math inline">\(S_1\)</span>. <img src="https://img-blog.csdnimg.cn/20210519202838706.png" alt="在这里插入图片描述" /> Assume we got a performance of 20. Next we need to backpropagate the value to <span class="math inline">\(S_1\)</span> and <span class="math inline">\(S_0\)</span> and update Q and #visits. <img src="https://img-blog.csdnimg.cn/20210519203559429.png" alt="在这里插入图片描述" /> We finished the first iteration. 3. Second iteration Start from <span class="math inline">\(S_0\)</span>, since <span class="math inline">\(A_2\)</span> has not been expanded so we have to choose it. Then add <span class="math inline">\(S_2\)</span> to the tree and playout from here. <img src="https://img-blog.csdnimg.cn/2021051921175522.png" alt="在这里插入图片描述" /> Then backpropagate to <span class="math inline">\(S_2\)</span> and <span class="math inline">\(S_0\)</span>: <img src="https://img-blog.csdnimg.cn/20210519212028325.png" alt="在这里插入图片描述" /> 4. Third iteration From <span class="math inline">\(S_0\)</span> there are no unexpanded actions so we need to select one child using UCB (assume C=2). <span class="math inline">\(UCB(S_1)=21.67,UCB(S_2)=11.67\)</span>. Thus we select the leaf node <span class="math inline">\(S_1\)</span>. Assume <span class="math inline">\(S_1\)</span> has 2 unexpanded actions. Choose one randomly (assume <span class="math inline">\(S_3\)</span>) and playout from here and backpropagate, assume we get performance of 0: <img src="https://img-blog.csdnimg.cn/20210519212745377.png" alt="在这里插入图片描述" /> 5. Fourth iteration From root we should decide which one to select. Again using UCB: <span class="math inline">\(UCB(S_1)=11.48,UCB(S_2)=12.10\)</span>. So we choose <span class="math inline">\(S_2\)</span>. Assume there are two unexpanded actions so we randomly choose <span class="math inline">\(S_5\)</span> and playout and get a performance of 14. After backpropagate: <img src="https://img-blog.csdnimg.cn/20210519213431456.png" alt="在这里插入图片描述" /></p>
<p>Assume the max iteration number is 4 so we get the final tree above. Finally we can select the best solution from <span class="math inline">\(S_0\)</span> to leaf node according to UCB value.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/04/06/Bayesian%20Optimization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/04/06/Bayesian%20Optimization/" class="post-title-link" itemprop="url">Bayesian Optimization</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-04-06 14:18:00" itemprop="dateCreated datePublished" datetime="2021-04-06T14:18:00+08:00">2021-04-06</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="motivation">Motivation</h2>
<p>Hyper-parameters tuning has become an important work during training neural networks. As the number of Hyper-parameter is becoming larger, researchers proposed Grid Search &amp; Random Search to wish to get better combinations of Hyper-parameters. However, Grid Search has a high time cost. Although some experiments showed that Random Search got a better result than Grid Search but the result is still not fulfilling.</p>
<p>Besides, there are some gradient-based methods to solve the problem. But the objective function is usually not differentiable or even not continuous. Thus these methods have a very finite usage.</p>
<p>BO is a gradient-free optimization method to get global solutions of a black-box function. The function usually has a high cost to compute such as training a deep neural network after tuning the Hyper-parameters. For this reason, we usually find a <strong>surrogate</strong> function to approximate the original function <span class="math inline">\(f\)</span>. In the field of AutoML, we often use Gaussian Process, Random Forest or deep network as the surrogate model. The simplest form of BO is as follows: <img src="https://img-blog.csdnimg.cn/20210401193953429.png" alt="在这里插入图片描述" /> <span class="math inline">\(f\)</span> represents the black-box function that we want to optimize (black-box means that the function transforms a configuration <span class="math inline">\(x\)</span> to an output but we don't know the exact function relationship). <span class="math inline">\(\chi\)</span> represents the search space of the combination of hyper-parameters. <span class="math inline">\(S\)</span> represents <strong>Acquisition Function</strong> which is used to select the promising <span class="math inline">\(x\)</span>. <span class="math inline">\(M\)</span> represents the surrogate model which takes a configuration <span class="math inline">\(x\)</span> and outputs the performance (much like <span class="math inline">\(f\)</span> does).</p>
<p>First we need to get some samples from <span class="math inline">\((f,\chi)\)</span>, thus we get <span class="math inline">\(D=(x_i,f(x_i)), i=1...n\)</span>.</p>
<p>Next we iterate <span class="math inline">\(T\)</span> times (often fixed) to select configuration <span class="math inline">\(x\)</span>. Use the dataset <span class="math inline">\(D\)</span> to train the surrogate model <span class="math inline">\(M\)</span> (much easier than train <span class="math inline">\(f\)</span>). <span class="math inline">\(M\)</span> has several choices such as Random Forest, Tree Parzen Estimators. Here we use GP so we get the probabilistic model <span class="math inline">\(p(y|x,D)\)</span>.</p>
<p>Then we need to find the most promising configuration <span class="math inline">\(x\)</span>. The most important thing for Acquisition Function is to make a balance between <strong>exploration &amp; exploitation</strong>. It means that when selecting the next <span class="math inline">\(x\)</span> we not only want to select those untried points (exploration) but also want to select those tried points which has a great <span class="math inline">\(f(x)\)</span> (exploitation).</p>
<p>Finally use the promising <span class="math inline">\(x_i\)</span> to get corresponding performance <span class="math inline">\(y_i\)</span> and join the pair into <span class="math inline">\(D\)</span>. ## Gaussian Process If we assume <span class="math inline">\(x_i\)</span> is independent with each other, the Multivariant Gaussian Distribution's probability density is as follows: <span class="math display">\[
p(x_1,...,x_n)=\frac{1}{(2\pi)^{\frac{n}{2}}\sigma_1...\sigma_n}exp(-\frac{1}{2}[\frac{(x_1-\mu_1)^2}{\sigma_1^2}+...+\frac{(x_n-\mu_n)^2}{\sigma_n^2}])
\]</span> We can rewrite the formula to the vectorized version: <span class="math display">\[
p(x)=(2\pi)^{-\frac{n}{2}}|K|^{-\frac{1}{2}}exp[-\frac{1}{2}(x-\mu)^TK^{-1}(x-\mu)]
\]</span> in which <span class="math display">\[
K=\left[
\begin{matrix}
  \sigma_1^2     &amp; 0      &amp; \cdots &amp; 0      \\
 0      &amp; \sigma_2^2      &amp; \cdots &amp; 0      \\
 \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
 0     &amp; 0      &amp; \cdots &amp; \sigma_n^2     \\
\end{matrix}
\right], x-\mu=[x_1-\mu_1,...,x_n-\mu_n]^T
\]</span> Thus <span class="math inline">\(x\sim N(\mu,K)\)</span>, <span class="math inline">\(\mu\)</span> is the mean vector and <span class="math inline">\(K\)</span> is the covariance matrix (a diagonal matrix since the independence).</p>
<p>But what should we do when <span class="math inline">\(x\)</span> has infinite dimensions? Such as in a continuous temporal T or spatial S. Actually GP means Gaussian Distribution and Stochastic Process (about time T). GP is defined by an infinite number of Random Variables on a continuous domain. In other words, it is an infinite dimension Gaussian Distribution. Formally, let's sample n moments from T: <span class="math inline">\(t_1,...,t_n\in T\)</span>, thus we get a n-dimensional vector <span class="math inline">\((\xi_1,...,\xi_n)\)</span>, if this vector is a n-dimensional Gaussian Distribution then <span class="math inline">\({\xi_t}\)</span> is a GP.</p>
<p>Let's take an easy example to illustrate: suppose during peoples' life time, at every moment <span class="math inline">\(t\)</span> the energy of the population forms a Gaussian Distribution but different moments have different <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>: <img src="https://img-blog.csdnimg.cn/20210404141525979.png" alt="在这里插入图片描述" /> If we take 5 moments during a population's life time, then <span class="math inline">\(\xi_1-\xi_5\)</span> all forms Gaussian Distribution but they have different <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. If we sample an arbitrary moment <span class="math inline">\(t\)</span> then <span class="math inline">\(\xi(t)\sim N(\mu_t,\sigma_t^2)\)</span>. If we sample at some points and connect them together we get two samples of the GP, as the figure shows.</p>
<p>Now that we know what happens at <span class="math inline">\(t\)</span>, let's consider the whole <span class="math inline">\(T\)</span>. We know that for a finite Gaussian Distribution, it can be determined by a n-dimensional vector <span class="math inline">\(\mu_n\)</span> (reflects every Random Variable's expectation) and a <span class="math inline">\(n\times n\)</span> matrix <span class="math inline">\(\Sigma\)</span> (reflects every RV's variances and covariance between different dimensions). It is almost the same for GP except that we cannot use a vector to describe every <span class="math inline">\(t\)</span>'s mean since it is infinite. So we need a function <span class="math inline">\(m(t)\)</span> to describe the continuous <span class="math inline">\(T\)</span>. For <span class="math inline">\(\Sigma\)</span> we should use a kernel function <span class="math inline">\(k(s,t)\)</span> to describe the covariance between time <span class="math inline">\(t\)</span> and <span class="math inline">\(s\)</span>. Once <span class="math inline">\(m(t)\)</span> and <span class="math inline">\(k(s,t)\)</span> is defined the GP is determined <span class="math inline">\(\xi_t\sim GP(m(t),k(s,t))\)</span>.</p>
<p>The most popular kernel function is RBF which is defined as follows: <span class="math display">\[k(s,t)=\sigma^2exp(-\frac{||s-t||^2}{2l^2})\]</span> <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(l\)</span> are two hyper-parameters. If <span class="math inline">\(s\)</span> and <span class="math inline">\(t\)</span> are close in <span class="math inline">\(T\)</span> then the output covariance will be larger and it means the correlation between the two points is bigger.</p>
<p>Once we have some knowledge about GP we can start to know Gaussian Process Regression, which is a kind of Probabilistic Model. It means that we can use Prior and Observations to calculate Posterior. First we define a GP by <span class="math inline">\(m(t)\)</span> and <span class="math inline">\(k(s,t)\)</span>, which is a Prior. Then we observe some data to revise the GP's <span class="math inline">\(m(t)\)</span> and <span class="math inline">\(k(s,t)\)</span> to get Posterior. But how?</p>
<p>Here we need to use some Gaussian Distribution's nice properties: Once Gaussian always Gaussian. It means that marginal distribution, summation and conditional distribution of a GD are still GD. Assume a n-dimensional RV <span class="math inline">\(x\sim N(\mu,\Sigma)\)</span> and we divide it into two parts <span class="math inline">\(x_A\)</span> and <span class="math inline">\(x_B\)</span> then we get: <span class="math display">\[x=\begin{bmatrix} x_A\\ x_B \end{bmatrix},\mu=\begin{bmatrix} \mu_A\\ \mu_B \end{bmatrix},\Sigma=\begin{bmatrix} \Sigma_{AA}, \Sigma_{AB} \\ \Sigma_{BA}, \Sigma_{BB} \end{bmatrix}\]</span> Then we can get: <span class="math display">\[x_A|x_B\sim \mathcal{N}(\mu_A+\Sigma_{AB}\Sigma_{BB}^{-1}(x_B-\mu_B),\Sigma_{AA}-\Sigma_{AB}\Sigma_{BB}^{-1}\Sigma_{BA})\]</span> Thus we could update the GD's Posterior parameters. It is much the same in GP. If we get some samples <span class="math inline">\((X,Y)\)</span> then the rest is <span class="math inline">\((X^*,f(X^*))\)</span>. The joint distribution forms an infinite GD: <span class="math display">\[\begin{bmatrix} Y\\ f(X^*) \end{bmatrix}\sim N(\begin{bmatrix} \mu(X)\\ \mu(X^*) \end{bmatrix},\begin{bmatrix} k(X,X), k(X,X^*) \\ k(X^*,X), k(X^*,X^*) \end{bmatrix})\]</span> So we want to know the rest of the points based on the observed points: <span class="math inline">\(f(X^*)|Y\sim N(\mu^*,k^*)\)</span>. <span class="math display">\[\mu^*=\mu(X^*)+k(X^*,X)k(X,X)^{-1}(Y-\mu(X))\\
k^*=k(X^*,X^*)-k(X^*,X)k(X,X)^{-1}k(X,X^*)\]</span> Here is an example: <img src="https://img-blog.csdnimg.cn/20210404155244142.png" alt="在这里插入图片描述" /> Finally let's return back to our BO's <span class="math inline">\(M\)</span>. We first assume our prior: <span class="math inline">\(\mu(X)=0,k(X,X^*)=RBF\)</span>. Plus the observed and evaluated <span class="math inline">\(D=\{x_i,y_i\}\)</span> we can get <span class="math inline">\(\hat \mu\)</span> and <span class="math inline">\(\hat{\sigma}^{2}\)</span>, then the posterior prediction is <span class="math inline">\(p(y|x,D)\)</span>, which is still a Gaussian Distribution. The calculation process is as follows: <span class="math display">\[
y=(y_1,...,y_i)^T \\
\hat \mu=k^T(x)(k+\sigma_{n}^{2}I)^{-1}y \\
\hat{\sigma}^{2}=k(x^*x)-k(x)^T(k+\sigma_{n}^{2}I)^{-1}k(x)
\]</span> Once we get the posterior prediction <span class="math inline">\(p(y|x,D)\)</span>, we can feed them to the Acquisition Function to get next <span class="math inline">\(x_t\)</span>. ## Acquisition Function There are some popular Acquisition Functions:</p>
<ol type="1">
<li>Upper Confidence Bound (UCB) <span class="math inline">\(x_{t+1}=\underset{x\in X}{\operatorname{arg\ max}}[\mu_{t}(x)+\beta_t^{1/2}\sigma_t(x)]\)</span> The weighted sum of posterior mean and posterior standard deviation. The two items correspond exploitation and exploration, respectively.</li>
<li>Expected Improvement (EI) <span class="math inline">\(x_{t+1}=\underset{x\in X}{\operatorname{arg\ max}}\ E_{f(x)\sim N(\mu_{t}(x),\sigma_t^2(x))}[max(0,f(x)-f_t^+)]\)</span>, <span class="math inline">\(f_t^+\)</span> is the max observation value during the first <span class="math inline">\(t\)</span> iterations.</li>
</ol>
<p>Except the above functions, there are Probability of Improvement, Entropy Search and so on. ## Reference <a target="_blank" rel="noopener" href="https://jgoertler.com/visual-exploration-gaussian-processes/">A Visual Exploration of Gaussian Processes</a> <a target="_blank" rel="noopener" href="https://www.zhihu.com/question/46631426">如何通俗易懂地介绍Gaussian Process</a> <a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/76269142">贝叶斯优化/Bayesian Optimization</a> <a target="_blank" rel="noopener" href="https://github.com/fmfn/BayesianOptimization/blob/master/examples/exploitation_vs_exploration.ipynb">Exploitation vs Exploration</a> <a target="_blank" rel="noopener" href="https://github.com/fmfn/BayesianOptimization">BayesianOptimization</a> <a target="_blank" rel="noopener" href="https://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/lecturenote15.html">Lecture 15: Gaussian Processes</a> <a target="_blank" rel="noopener" href="https://distill.pub/2020/bayesian-optimization/">Exploring Bayesian Optimization</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/03/29/Inductive%20Representation%20Learning%20on%20Large%20Graphs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/29/Inductive%20Representation%20Learning%20on%20Large%20Graphs/" class="post-title-link" itemprop="url">Inductive Representation Learning on Large Graphs</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-03-29 08:56:00" itemprop="dateCreated datePublished" datetime="2021-03-29T08:56:00+08:00">2021-03-29</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>Stanford的帅哥Jure发在NIPS 2017的一篇文章。</p>
<p>GCN是Transductive Learning，训练时的图要包含所有结点，是固定的，不能快速泛化到未知结点（图），本文提出了一种Inductive Learning的GraphSAGE。</p>
<p>GCN学习的是每个单独节点的低维embedding，由于输入的图是固定的，所以可以很好捕获全局信息。但如果要获得新节点的embedding，加入图以后需要调整其它结点，至少也是局部重新训练，计算开销太大，应用受限。</p>
<p>GraphSAGE学习的不是每个结点的固定的表示，因为图结构不断变化，所以学习一种节点表示的函数，这样就可以快速得到未知结点的表示。</p>
<p>简单来说：学习每个结点的特征如何由邻居的特征聚合而来，学到聚合函数后，只要已知新节点的特征和邻边关系，就能得到表示，并且这个表示会由于图结构的变化而变化，是动态的。</p>
<p>前向传播是为了生成结点的向量表示， <img src="https://img-blog.csdnimg.cn/20210207163418476.png" alt="在这里插入图片描述" /> 如果聚合K次，就需要K个聚合函数，初始时每个结点的表示是原本的特征向量，对第k层，对结点v，先得到v的第k层结点的聚合表示，加上v在上一层的特征，最后得到v的最终表示。</p>
<p>以作者的图为例， <img src="https://img-blog.csdnimg.cn/20210220111424640.png" alt="在这里插入图片描述" /> 我觉得知乎上这张更清楚： <img src="https://img-blog.csdnimg.cn/20210220111932548.png" alt="在这里插入图片描述" /> 每一层的表示都是由上一层生成，与当前层其他节点无关。</p>
<p>由于需要学习参数，所以要设计损失函数。无监督学习的损失函数应该是让临近节点有相似的表示，有监督学习用cross-entropy即可。</p>
<p>聚合函数作者给了3种选择：</p>
<ol type="1">
<li>Mean 取邻居的平均值</li>
<li>LSTM</li>
<li>Pooling</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/03/13/Loss%20Function/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/13/Loss%20Function/" class="post-title-link" itemprop="url">Loss Function</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-03-13 11:08:00" itemprop="dateCreated datePublished" datetime="2021-03-13T11:08:00+08:00">2021-03-13</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>For binary classification (+1, -1), if we classify correctly then <span class="math inline">\(y\cdot f = y\cdot \theta^Tx\gt0\)</span>; otherwise <span class="math inline">\(y\cdot f = y\cdot\theta^Tx\lt0\)</span>. Thus we have following loss functions:</p>
<ul>
<li>0/1 loss <span class="math inline">\(\min_\theta\sum_i L_{0/1}(\theta^Tx)\)</span>. We define <span class="math inline">\(L_{0/1}(\theta^Tx) =1\)</span> if <span class="math inline">\(y\cdot f \lt 0\)</span>, and <span class="math inline">\(=0\)</span> o.w. Non convex and very hard to optimize.</li>
<li>Hinge loss Upper Bound of 0/1 loss. Approximate 0/1 loss by <span class="math inline">\(\min_\theta\sum_i H(\theta^Tx)\)</span>. We define <span class="math inline">\(H(\theta^Tx) = max(0, 1 - y\cdot f)\)</span>. Apparently <span class="math inline">\(H\)</span> is small if we classify correctly.</li>
<li>Logistic loss <span class="math inline">\(\min_\theta \sum_i log(1+\exp(-y\cdot \theta^Tx))\)</span>.</li>
</ul>
<p>Fortunately, hinge loss, logistic loss and square loss are all convex functions. Convexity ensures global minimum and it's computationally appealing. <img src="https://img-blog.csdnimg.cn/20210226181824674.png" alt="在这里插入图片描述" /> Figure 7.5 from Chris Bishop's PRML book. The Hinge Loss E(z) = max(0,1-z) is plotted in blue, the Log Loss in red, the Square Loss in green and the 0/1 error in black.</p>
<p>From the figure we can observe that the hard instance (near the boundary) will influence the loss function a lot so we need to make the model robust and can deal with the hard ones.</p>
<p>For binary classification we can unify the two cases (classify correctly or not) by <span class="math inline">\(y\cdot f\)</span>, but for multi-class classification (0, 1, 2, ..., k) we cannot unify all the cases. So we use cross-entropy as the loss.</p>
<p>There exists a vivid example for transform the target function: If a noisy picture is given, and want to output the clean one. Here the clean one is hard to control so we can let the noise be the target function and wo should minimize the amplitude of the noise. Thus the problem becomes controllable.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/03/05/BusTub/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/03/05/BusTub/" class="post-title-link" itemprop="url">BusTub</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-03-05 06:24:00" itemprop="dateCreated datePublished" datetime="2021-03-05T06:24:00+08:00">2021-03-05</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="project-0---c-primer"><a target="_blank" rel="noopener" href="https://15445.courses.cs.cmu.edu/fall2020/project0/">PROJECT #0 - C++ PRIMER</a></h2>
<p>这个Warm-Up主要是要熟悉C++ 17的一些Features，只需要实现<code>p0_starter.h</code>即可； 提交gradescope，要上传zip文件，但是路径总是不对，文档里也说得不明不白，一定要加上路径名：<code>zip solution.zip src/include/primer/p0_starter.h</code>； <code>unique_ptr</code>拥有对象的独占权，可以用<code>move</code>将对象的所有权转移到另一个<code>unique_ptr</code>。</p>
<p>第一次提交时有内存安全隐患： <img src="https://img-blog.csdnimg.cn/20201227221401866.png" alt="在这里插入图片描述" /> 网上说可能是valgrind版本过低，用高版本测试后发现没问题： <img src="https://img-blog.csdnimg.cn/20201227221456847.png" alt="在这里插入图片描述" /> 其实代码是有bug的，经过测试，发现问题在于实现矩阵乘法时定义了临时变量<code>double tmp = 0.0</code>：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">double</span> tmp = <span class="number">0.0</span>;</span><br><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; mat1-&gt;<span class="built_in">GetColumns</span>(); ++k) &#123;</span><br><span class="line">  tmp += mat1-&gt;<span class="built_in">GetElem</span>(i, k) * mat2-&gt;<span class="built_in">GetElem</span>(k, j);</span><br><span class="line">&#125;</span><br><span class="line">ans-&gt;<span class="built_in">SetElem</span>(i, j, tmp);</span><br></pre></td></tr></table></figure>
<p>改为：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">int</span> k = <span class="number">0</span>; k &lt; mat1-&gt;<span class="built_in">GetColumns</span>(); ++k) &#123;</span><br><span class="line">  ans-&gt;<span class="built_in">SetElem</span>(i, j, ans-&gt;<span class="built_in">GetElem</span>(i, j) + mat1-&gt;<span class="built_in">GetElem</span>(i, k) * mat2-&gt;<span class="built_in">GetElem</span>(k, j));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>我个人理解是这样：因为原本代码中是模板参数<code>T</code>，如果定义<code>double</code>作为临时变量，测试时用<code>int</code>测试，最终<code>SetElem</code>时要存入<code>double</code>，但是预先分配的内存只有<code>int</code>大小，所以内存溢出报错。 <img src="https://img-blog.csdnimg.cn/20210127214548109.png" alt="在这里插入图片描述" /> ## <a target="_blank" rel="noopener" href="https://15445.courses.cs.cmu.edu/fall2020/project1/">PROJECT #1 - BUFFER POOL MANAGER</a> 整体要为<a target="_blank" rel="noopener" href="https://github.com/cmu-db/bustub">Bustub</a>做一个面向磁盘的存储管理系统： <img src="https://img-blog.csdnimg.cn/20210225225705723.png" alt="在这里插入图片描述" /> 第一次作业是要实现一个内存缓冲池：负责将物理页面在磁盘和主存之间移动，这样DBMS就可以支持比内存更大的数据库。缓冲池的操作对其它系统部件是透明的，比如系统通过唯一的页面标识符<code>page_id_t</code>向缓冲池要求访问页面，而不管页面是在内存中还是在磁盘上。</p>
<p>缓冲池的实现必须是线程安全的，多个线程同时访问时需要用latches保护（OS中叫locks）。 关于DBMS中的🔒： - locks：高层次的逻辑原语，在事务的整个执行过程中保护数据库的内容（元组/表/数据库），可以rollback - latches：低层次的保护原语，DBMS用来保护内部数据结构的安全访问（hash table, regions of memory），只在某个具体操作时使用，不可以rollback</p>
<p>具体来说：有2部分：LRU替换策略+缓冲池管理 - LRU LRU的实现有多种方式： 1、数组+时间戳：每次插入新数据项的时候，先把数组中存在的数据项的时间戳自增，并将新数据项的时间戳置为0并插入到数组中。每次访问数组中的数据项的时候，将被访问的数据项的时间戳置为0。当数组空间已满时，将时间戳最大的数据项淘汰。 2、双向链表：每次新插入数据的时候将新数据插到链表的头部；每次缓存命中（即数据被访问），则将数据移到链表头部；那么当链表满的时候，就将链表尾部的数据丢弃。 上面两种复杂度均是O(n) 3、双向链表+Hash Map：当需要插入新的数据项的时候，如果新数据项在链表中存在（一般称为命中），则把该节点移到链表头部，如果不存在，则新建一个节点，放到链表头部，若缓存满了，则把链表最后一个节点删除即可。在访问数据的时候，如果数据项在链表中存在，则把该节点移到链表头部，否则返回-1。这样一来在链表尾部的节点就是最近最久未访问的数据项。本质上是list看作时间戳，hash table记录元素值到链表位置的映射关系，get和put均是O(1)。 - 缓冲池管理 缓冲池的组织形式是frame数目固定的数组，访问时将page从磁盘拷贝到frame。 与OS内存管理相似，也需要有page table记录哪些page在buffer pool中，page id -&gt; frame id；page directory记录了磁盘上的位置，page id -&gt; page locations in disk。 还需要有dirty位以及pin/ref counter记录当前正在访问的线程数目，只有flush或者置换脏页时才写回磁盘。 <img src="https://img-blog.csdnimg.cn/2021022523062865.png" alt="在这里插入图片描述" /> 缓冲池和<code>Replacer</code>的大小是相同的，如果page的ref counter变为0时就可以加入到<code>Replacer</code>中作为替补牺牲页面。</p>
<p>从缓冲池中根据ID fetch的时候有3种情况： 1. 如果page在缓冲池，直接返回； 2. 如果不在，但缓冲池有空闲frame，从磁盘读取page放入该frame； 3. 如果不在且缓冲池没有空闲frame，从buffer中牺牲一页，从磁盘读取page放入对应的frame。</p>
<p>第一次提交忘了处理并发问题，只得了65分： <img src="https://img-blog.csdnimg.cn/20210209211524362.png" alt="在这里插入图片描述" /> 加了一些🔒后，还有2个test挂了： <img src="https://img-blog.csdnimg.cn/20210209215248107.png" alt="在这里插入图片描述" /> <code>isdirty</code>一直过不去，后来在群里看到：只有page当前的脏位是false且传入<code>is_dirty==true</code>时才需要修改当前的脏位。这里我是这么理解的：如果页面应该标记为dirty那么传入的参数就是true： - 当前为true &amp;&amp; <code>is_dirty==true</code>：页面修改过，也做了正确标记，不用管； - 当前为false &amp;&amp; <code>is_dirty==true</code>：页面其实修改过，但没有标记，改正； - 当前为false &amp;&amp; <code>is_dirty==false</code>：页面没修改，标记正确，不用管； - 当前为true &amp;&amp; <code>is_dirty==false</code>：页面没修改，标记为修改过，这种也不用管，大不了置换时写回磁盘耗费些时间。 <img src="https://img-blog.csdnimg.cn/20210210204925713.png" alt="在这里插入图片描述" /> 数据库真的太难了，尤其是涉及到并发控制的部分，我真的没有足够时间去debug这些，以后有空再继续做吧。。 ## <a target="_blank" rel="noopener" href="https://15445.courses.cs.cmu.edu/fall2020/project2/">PROJECT #2 - B+ TREE</a> ## <a target="_blank" rel="noopener" href="https://15445.courses.cs.cmu.edu/fall2020/project3/">PROJECT #3 - QUERY EXECUTION</a> ## <a target="_blank" rel="noopener" href="https://15445.courses.cs.cmu.edu/fall2020/project4/">PROJECT #4 - CONCURRENCY CONTROL</a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="EIMadrigal"
      src="/images/favicon.png">
  <p class="site-author-name" itemprop="name">EIMadrigal</p>
  <div class="site-description" itemprop="description">Hello World</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">167</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/EIMadrigal" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;EIMadrigal" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:andrew.renj@gmail.com" title="E-Mail → mailto:andrew.renj@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.cnblogs.com/EIMadrigal" title="cnblogs → https:&#x2F;&#x2F;www.cnblogs.com&#x2F;EIMadrigal" rel="noopener" target="_blank"><i class="fab fa-codiepie fa-fw"></i>cnblogs</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/EIMadrigal" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;EIMadrigal" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2018-02 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">EIMadrigal</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">Total views: <span id="busuanzi_value_site_pv"></span></span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">Total visitors: <span id="busuanzi_value_site_uv"></span></span>
    <span class="post-meta-divider">|</span>

<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);
    var countOffset = 20000;

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset);
            clearInterval(int);
        }  
    }
       	
});
</script> 

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


</body>
</html>
