<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.0.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"eimadrigal.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"manual","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="Hello World">
<meta property="og:type" content="website">
<meta property="og:title" content="EI Madrigal&#39;s Space">
<meta property="og:url" content="https://eimadrigal.github.io/page/2/index.html">
<meta property="og:site_name" content="EI Madrigal&#39;s Space">
<meta property="og:description" content="Hello World">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="EIMadrigal">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://eimadrigal.github.io/page/2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>EI Madrigal's Space</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">EI Madrigal's Space</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content index posts-expand">
            
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/09/11/%E4%BB%80%E4%B9%88%E6%98%AF%E6%B1%9F%E6%B9%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/09/11/%E4%BB%80%E4%B9%88%E6%98%AF%E6%B1%9F%E6%B9%96/" class="post-title-link" itemprop="url">什么是江湖</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-09-11 15:24:00" itemprop="dateCreated datePublished" datetime="2021-09-11T15:24:00+08:00">2021-09-11</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>周一老板通知我周四去MSRA分享下自己的工作，我又惊又喜：喜的是自己有生之年竟然会有机会去dream company给talk，惊的是自己的工作实在很简单拉跨。接下来几天我全力做PPT，确认每一个技术细节，担心被问得下不来台，这也是我到目前为止见过的最大场面，所以压力极大，甚至吃不下饭、睡不着觉。</p>
<p>期间小老板还一直催着改论文，经常一个电话过来搞得我有点烦。可能真的是累了，烦了，也可能是被老师说创新性和工作量都不大，或者是要去微软分享过于紧张，总之现在过的有些痛苦，我基本彻底不想搞科研了，甚至不想毕业干码农了。可是真的不知道在金钱和妥协之间如何选择，到底是： 1. 能忍受互联网的工作环境，然后攒点钱去做其他事 2. 实在忍受不了，过的也比较痛苦，毕业直接去当老师 这个问题可能只有去不同地方实习才会有答案/与工作的同学交流，看看什么情况。 和赵欣倾诉下吧~</p>
<p>到北京后才知道被鸽了，得知这次只能参观一圈，改为下周四线上会议，我如释重负。虽然没有完美成行，但是和老板以及MSRA密切交流还是有了一些收获：</p>
<ol type="1">
<li>通过和老板以及MSRA的一些交流，学术水平或者学习水平重要，但是更重要的是圈子，人脉，关系。江湖不是打打杀杀，而是人情世故。</li>
<li>学会错位发展。如果一件事情很火，那么可能就要小心点，你未必卷的过，就像ML组基本进不了，但是生信组却坑多，容易进，同时也显示了信息的重要。</li>
<li>自己的水平以及做的东西至少要达到一个差不多的标准，这样在老板的人脉发挥作用时才不至于错失良机。</li>
<li>许多事不要用类比的眼光去看，政策永远在动态调整，背后可能牵扯了很多故事，这是浮在表面的我们看不到的。</li>
<li>不出来见见世面，永远不会被打醒。创新港永远是一个鸟不拉屎的地方，长期在那里只会禁锢思想，自甘堕落。不要小瞧环境对人潜移默化的影响。</li>
<li>中美关系的影响我第一次如此真切的感受到，微软要听美国爸爸的话，人脸识别做不了，外企的特色文化也很敏感。</li>
</ol>
<p>还有就是自己无论见识，能力都差的很远，今天的聊天我几乎是透明的。感觉真的越来越土了，我真的太差了，想想自己的水平，万一真的被派到MSRA实习，又怎么能胜任呢？</p>
<p>还有就是以后再给自己太大压力了吧，有多大锅下多少米，有多大能力就干多少事吧。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/08/30/How%20to%20Make%20Plans/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/08/30/How%20to%20Make%20Plans/" class="post-title-link" itemprop="url">How to Make Plans</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-08-30 15:09:00" itemprop="dateCreated datePublished" datetime="2021-08-30T15:09:00+08:00">2021-08-30</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>如何平衡好科研、自学、生活？这是一个非常重要的问题，关乎未来发展和生活质量，并且随着年龄增长这个问题会变得更加严重，因为我们将要面临的世界会更加纷繁复杂。</p>
<p>要处理好这个问题并不容易，甚至有些玄学、有些艺术。我个人觉得解决这个问题的关键在于计划：制定合理的、可行的、有侧重性的、不那么死板、也不那么松散随意的计划，这其中包括长期计划、中期计划和短期计划，并且还要学会巧妙利用时间。</p>
<p>我自己尝试过各种各样的计划，包括但不限于按照时间段严格限定任务、按照任务进展松散型、TODO List等，基本都是坚持不到2礼拜就废弃了，而且也没有贯彻长期和中期计划。 <img src="https://img2020.cnblogs.com/blog/1260581/202112/1260581-20211223092219887-1893756805.png" alt="image" /></p>
<p>如果纯粹按照follow your heart去排序，那么毫无疑问是生活&gt;自学&gt;科研，但是问题在于需要保证科研的最低限度（实习及毕业），所以计划应该怎么定呢？</p>
<ol type="1">
<li>长期计划（2021.7~2025.7）：毕业工作两年。</li>
<li>中期计划（2021.7~2023.7）：</li>
<li>短期计划（每月每周）：</li>
</ol>
<p>核心问题在于：计划的目的并不在于100%完成，这听起来可能有些荒谬，计划的真正目的在于使你有一个为之努力的东西，全身心地投入到这个过程中，自然而然最后的结果也不会太差劲。所以TODO List中的事项没有全部划掉并不可怕，完成70%~80%足矣。剩下未完成的部分视重要程度作为下一阶段的首当其冲的事项。</p>
<p>达成目标本身并不会提高幸福水平的baseline，只是让自己future-oriented</p>
<h2 id="from-2021.11.23-to-2022.12.31">From 2021.11.23 To 2022.12.31</h2>
<p><strong>这段时间非常非常关键，会决定第一份工作的去向！！！绝对不能每天每个小时浑浑噩噩</strong></p>
<p>本计划包括阶段性目标和短期计划两部分，从后端开发（系统编程/云计算）的岗位需求出发设计目标：</p>
<p>阶段性目标主要是在什么时间节点完成什么事情，短期计划会具体到每天甚至每个小时的安排。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/07/28/Inspiring%20Quotes/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/28/Inspiring%20Quotes/" class="post-title-link" itemprop="url">Inspiring Quotes</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-07-28 02:57:00" itemprop="dateCreated datePublished" datetime="2021-07-28T02:57:00+08:00">2021-07-28</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <ol type="1">
<li>还差得远呢！ -ddd 深夜看到ddd对2020年华为软件比赛的精准<a target="_blank" rel="noopener" href="https://github.com/justarandomstring/2020-Huawei-Code-Craft">分析</a>，深感自己平日实在太过轻松。</li>
<li>天赋游戏，遥不可及。 一位计算机同学的个性签名，深感自己早已不可能成为最顶尖的那批人，借此来宽慰遇到麻烦时的窘境。</li>
<li>所有的优越感都是因为没有见识。</li>
<li>深夜里碰杯，都是梦破碎的声音。</li>
<li>I'm tired of all those boring comparisons.</li>
<li>Missing your Vanilla Sky.</li>
<li>消失在人海。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/07/26/767%20Reorganize%20String/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/26/767%20Reorganize%20String/" class="post-title-link" itemprop="url">767 Reorganize String</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-07-26 07:21:00" itemprop="dateCreated datePublished" datetime="2021-07-26T07:21:00+08:00">2021-07-26</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://leetcode.com/problems/reorganize-string/" title="题目链接">题目链接</a> ## 题意 给定字符串，重排其中的字符使得任意两个相邻位置的字母不同。 样例：s="aab"，输出"aba" ## 分析 最开始的想法是贪心+双指针，指针i从前向后遍历，指针j从i+1开始，如果s[i]==s[j]，j不断向后遍历找到第一个与s[i]不同的字母s[k]，将s[k]与s[j]交换。WA在了"baaba"，期待"ababa"，输出""，所以这种贪心策略显然是错的。</p>
<p>接着就想到需要考虑字符的出现频率，先按频率高低排序再去按照上述贪心，WA在了"aabbcc"，期待"abacbc"，输出""，很显然这种贪心策略本身就是错的。</p>
<p>接着就想到先安排出现次数最多的，如果当前要安排的与前一个字符相同，就选择出现次数第二多的，这样交替下去，可以写出如下代码： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def reorganizeString(self, s: str) -&gt; str:</span><br><span class="line">        if len(s) == 1:</span><br><span class="line">            return s</span><br><span class="line"></span><br><span class="line">        from collections import Counter</span><br><span class="line">        dic = Counter(s)</span><br><span class="line"></span><br><span class="line">        ans = &quot;&quot;</span><br><span class="line">        prev = &quot;&quot;</span><br><span class="line">        for i in range(0, len(s)):</span><br><span class="line">            cnts = list(dic.items())</span><br><span class="line">            cnts = sorted(cnts, key=lambda x:x[1], reverse=True)</span><br><span class="line">            if prev == cnts[0][0]:</span><br><span class="line">                if len(cnts) &lt;= 1 or cnts[1][1] == 0:</span><br><span class="line">                    return &quot;&quot;</span><br><span class="line">                ans += cnts[1][0]</span><br><span class="line">                dic[cnts[1][0]] -= 1</span><br><span class="line">                prev = cnts[1][0]</span><br><span class="line">            else:</span><br><span class="line">                ans += cnts[0][0]</span><br><span class="line">                dic[cnts[0][0]] -= 1</span><br><span class="line">                prev = cnts[0][0]</span><br><span class="line">        return ans</span><br><span class="line"></span><br></pre></td></tr></table></figure> 时间复杂度<span class="math inline">\(O(n^2lgn)\)</span>，空间<span class="math inline">\(O(n)\)</span>。</p>
<p>因为涉及到出现次数最多的问题，可以考虑max heap。每次迭代时，从堆里弹出堆顶元素（意味着下次迭代该元素不会考虑）加入res，如果上一次迭代加入res的元素还有剩余，就将其重新加入heap，意味着下次迭代需要考虑该元素。 <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">class Solution:</span><br><span class="line">    def reorganizeString(self, s: str) -&gt; str:</span><br><span class="line">        ans, cnt = [], Counter(s)  # decent order</span><br><span class="line">        max_heap = [(-value, key) for key, value in cnt.items()]</span><br><span class="line">        heapq.heapify(max_heap)</span><br><span class="line">        prev_ch, prev_cnt = &#x27;&#x27;, 0</span><br><span class="line">        while max_heap:</span><br><span class="line">            cnt, ch = heapq.heappop(max_heap)</span><br><span class="line">            ans.append(ch)</span><br><span class="line">            if prev_cnt &lt; 0:</span><br><span class="line">                heapq.heappush(max_heap, (prev_cnt, prev_ch))</span><br><span class="line">            cnt += 1</span><br><span class="line">            prev_ch, prev_cnt = ch, cnt</span><br><span class="line">        if len(s) != len(ans):</span><br><span class="line">            return &quot;&quot;</span><br><span class="line">        return &#x27;&#x27;.join(ans)</span><br></pre></td></tr></table></figure> 时间复杂度<span class="math inline">\(O(n)\)</span>，空间<span class="math inline">\(O(n)\)</span>。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/07/21/CS231n%20Assignment%20#1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/21/CS231n%20Assignment%20#1/" class="post-title-link" itemprop="url">CS231n Assignment</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-07-21 05:29:00" itemprop="dateCreated datePublished" datetime="2021-07-21T05:29:00+08:00">2021-07-21</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>先吹一波Google Colab，所有操作都可在云上进行，还能白嫖🐕家的GPU；再吹一下Stanford的骨架代码，真的是干净整洁优美，堪称典范。 <a target="_blank" rel="noopener" href="https://github.com/EIMadrigal/CS231n">My Code</a> ## kNN 最幼稚的机器学习算法。</p>
<ol type="1">
<li>计算测试集和训练集的距离 训练集<code>X_train</code>的shape为<span class="math inline">\((N, D)\)</span>，<code>y_train</code>的shape为<span class="math inline">\((N,)\)</span>，<code>y[i]</code>取值范围<span class="math inline">\([0,C-1]\)</span> 测试集<code>X_test</code>的shape为<span class="math inline">\((M, D)\)</span>，最终的distance matrix的shape为<span class="math inline">\((M,N)\)</span> 声明：不能使用类似于<code>np.linalg.norm()</code>这种东西作弊。 首先来看看2重循环：第一重遍历测试集，第二重遍历训练集，当然如果你愿意，还可以用第三重遍历dimension去累加距离； 再来看看只遍历测试集的单层循环：对于每个测试样例<code>X[i]</code>，减去<code>X_train</code>，通过广播机制得到一个<span class="math inline">\((N, D)\)</span>的差矩阵，做element-wise的平方，按列相加得到<span class="math inline">\((N,)\)</span>，表示测试样例<code>X[i]</code>与每个训练样例的距离，作为距离矩阵的第<span class="math inline">\(i\)</span>行； 最后来看看full-vectorized的版本，数学推导见<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/146076139">NumPy之计算两个矩阵的成对平方欧氏距离</a>，吃饱没事干的同学可以自己推推，我数学太差就溜了。</li>
<li>根据距离矩阵预测测试集的标签 对于每个测试样例<code>X[i]</code>，选k个距离最小的训练样例，将其label（从<code>y_train</code>获得）存入<code>cloest_y</code>中，投票决定最终的预测标签。 先用<code>idx=np.argsort(dists[i])[:k]</code>取出前k个训练样例的index，再用<code>y_train[idx]</code>得到对应的k个label，最后用<code>np.argmax(np.bincount(cloest_y))</code>得到最终的预测label。</li>
</ol>
<p>kNN效果当然比较拉垮了，在CIFAR-10的子集上分类正确率大概在27%左右。比较令我震惊的是三个计算距离函数耗费的时间，2重循环57s，单层循环41s，fully-vectorized只有0.57s，竟然<strong>降低了100倍</strong>，写出高效的代码对于程序性能有着至关重要的影响，反思下自己写出的junk code，不由得留下了伤心的泪水...</p>
<p>最后就是用cross-validation确定超参k的取值，就略过了哈。 ## Linear Multiclass SVM 首先要为多分类SVM写一个损失函数，老规矩还是先写一个naive版本<code>svm_loss_naive(W, X, y, reg)</code>： 权重矩阵W：<span class="math inline">\((D, C)\)</span> minibatch输入X：<span class="math inline">\((N, D)\)</span> 标签y：<span class="math inline">\((N,)\)</span>，<code>y[i]=c</code>表示<code>X[i]</code>的标签是c，<span class="math inline">\(0 \leq c&lt;c\)</span> <span class="math display">\[l=&quot;\frac{1}{N}&quot; \]</span>l_i="_{j" +="" -="" )="" ),s_j="f(x_i," ="" ="" _i="" <em>k<em>l="" </em>{j="" f(x_i;="" loss为：="" loss和正则项两部分，对于第<span class="math inline">\(i\)</span>个训练样本，data="" loss是这么定义的：="" machine="" multiclass="" s_j="" s</em>{y_i}="" support="" vector="" w)_j="" w)_j<span class="math display">\[=&quot;&quot; w)_{y_i}=&quot;&quot; w_{k,l}^2\]</span>="" y_i}="" 什么意思呢？<span class="math inline">\(s\)</span>是第<span class="math inline">\(i\)</span>个训练样本的得分向量<span class="math inline">\((c,)\)</span>，<span class="math inline">\(s_{y_i}\)</span>表示正确标签的得分，<span class="math inline">\(s_j\)</span>表示其他类的得分。不妨看看什么时候损失为0呢？稍作变形即有：当<span class="math inline">\(s_{y_i}-s_j=&quot;&quot; 看着有点复杂哦！主要有data=&quot;&quot; 返回浮点数`loss`和解析梯度`dw`=&quot;&quot;&gt;\Delta\)</span>时，第<span class="math inline">\(j\)</span>类损失为0，说人话就是只有当正确类的得分减去其他类的得分大于某个间隔<span class="math inline">\(\Delta\)</span>时才不会累积损失，否则就累加损失（必然为正数），这就是大名鼎鼎的<strong>Hinge Loss</strong>。</p>
<p>如果<span class="math inline">\(f\)</span>用的是linear score function，进一步有： <span class="math display">\[L_i = \sum_{j\neq y_i} \max(0, w_j^T x_i - w_{y_i}^T x_i + \Delta)\]</span> 其中，<span class="math inline">\(w_j\)</span>表示W的第<span class="math inline">\(j\)</span>列。 至此，naive版本的<code>loss</code>实现就不必废话了。接着来求<code>dW</code>，老规矩，还是先研究单个样本。</p>
<p>如果你的数学还行，下面的梯度推导可以略过： <span class="math display">\[L_i = max(0,w_1^T x_i - w_{y_i}^T x_i + \Delta)+max(0,w_2^T x_i - w_{y_i}^T x_i + \Delta)+...+max(0,w_C^T x_i - w_{y_i}^T x_i + \Delta)\]</span> 共有<span class="math inline">\(C-1\)</span>项，因为<span class="math inline">\(j=y_i\)</span>那项不算。另，只有在<span class="math inline">\(w_j^T x_i - w_{y_i}^T x_i + \Delta&gt;0\)</span>时第<span class="math inline">\(j\)</span>项的梯度不为0。</p>
<ol type="1">
<li>对<span class="math inline">\(w_{y_i}\)</span>的梯度 每项都有，并且都是0或<span class="math inline">\(-x_i\)</span>，因此只要看几项大于0，梯度就是几倍的<span class="math inline">\(-x_i\)</span>，正式点就是： <span class="math display">\[\nabla_{w_{y_i}} L_i = - \left( \sum_{j\neq y_i} \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta &gt; 0) \right) x_i\]</span></li>
<li>对<span class="math inline">\(w_j\)</span>的梯度 只有第<span class="math inline">\(j\)</span>项有，0或<span class="math inline">\(x_i\)</span>，正式点就是： <span class="math display">\[\nabla_{w_j} L_i = \mathbb{1}(w_j^Tx_i - w_{y_i}^Tx_i + \Delta &gt; 0) x_i\]</span></li>
</ol>
<p>naive版本的<code>dW[:,j]</code>和<code>dW[:,y[i]]</code>就2重循环按部就班更新即可，别忘了除以<span class="math inline">\(N\)</span>和正则项梯度。</p>
<p>接着来实现<code>svm_loss_vectorized(W, X, y, reg)</code>：</p>
<ol type="1">
<li>loss 首先求得整个训练集的得分矩阵<code>scores</code>，shape为<span class="math inline">\((N,C)\)</span>，每一行表示一个样例的得分。正确类得分向量<code>correct_class_score</code>可用<code>scores[np.arange(num_train), y]</code>得到，shape为<span class="math inline">\((N,)\)</span>，注意这里不能用<code>scores[:, y]</code>，简单试验下：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">X = np.array([[<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>],[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>]])</span><br><span class="line">y = np.array([<span class="number">2</span>, <span class="number">1</span>])</span><br><span class="line"><span class="built_in">print</span>(X[np.arange(<span class="number">2</span>), y])  <span class="comment"># [3,4]</span></span><br><span class="line"><span class="built_in">print</span>(X[:, y])  <span class="comment"># [[3,2],[5,4]]</span></span><br></pre></td></tr></table></figure>
<p>下来到了最关键的<code>margins</code>矩阵，该矩阵和<code>scores</code>矩阵shape相同<span class="math inline">\((N,C)\)</span>，第<span class="math inline">\(i\)</span>行表示第<span class="math inline">\(i\)</span>个训练样本的margin即<span class="math inline">\(max(0,s_j - s_{y_i} + \Delta)\)</span>，在每一行第<span class="math inline">\(y_i\)</span>个位置上应当设置为0，其余位置按照公式即可：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">margins = np.maximum(<span class="number">0</span>, scores - correct_class_score[:, np.newaxis] + <span class="number">1</span>)</span><br><span class="line">margins[np.arange(num_train), y] = <span class="number">0</span></span><br></pre></td></tr></table></figure>
<p>需要注意：<code>correct_class_score</code>是一个<span class="math inline">\((N,)\)</span>的向量，如果直接<code>scores-correct_class_score</code>就会报错，广播机制从最后一个维度开始比对，只有相等或者其中某个为1才行，因此用<code>np.newaxis</code>将<code>correct_class_score</code>的shape变为<span class="math inline">\((N,1)\)</span>；还有就是<code>np.max()</code>和<code>np.maximum()</code>的区别，<code>np.max()</code>和<code>np.amax(a, axis=None, ...)</code>等价，返回数组的最大值，<code>np.maximum(x1, x2, out=None, ...)</code>返回element-wise的较大值。</p>
<ol start="2" type="1">
<li>梯度 这里也稍微有点tricky，根据naive版本对梯度的讨论：对<span class="math inline">\(w_j\)</span>的梯度需要知道margin的正负，对<span class="math inline">\(w_{y_i}\)</span>的梯度需要知道<strong>有几项大于0</strong>。怎么借助<code>margins</code>矩阵统计每一行大于0的项数呢？无聊的程序员先将矩阵中大于0的项都设为1，然后按列相加即可：</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">margins[margins &gt; <span class="number">0</span>] = <span class="number">1.0</span></span><br><span class="line">num_to_loss = np.<span class="built_in">sum</span>(margins, axis=<span class="number">1</span>)  <span class="comment"># (N,)</span></span><br><span class="line">margins[np.arange(num_train, y)] = -num_to_loss</span><br></pre></td></tr></table></figure>
<p>对单个样本<span class="math inline">\(i\)</span>来说，其对<code>dW</code>的贡献要么是在第<span class="math inline">\(j\)</span>列（即第<span class="math inline">\(j\)</span>个类）加上<span class="math inline">\(x_i\)</span>，要么在第<span class="math inline">\(y_i\)</span>列加上<span class="math inline">\(-kx_i\)</span>，<span class="math inline">\(k\)</span>为<code>margins[i]</code>中大于0的元素个数，即<code>num_to_loss[i]</code>，整个训练集对<code>dW</code>的更新即是在累加单个样本对<code>dW</code>每一列（每个类）的影响。对第<span class="math inline">\(j\)</span>列，其更新即为每个训练样本对该类贡献的线性组合，组合系数取决于该样本的标签以及是否满足指示函数，即为<code>margins</code>的第<span class="math inline">\(j\)</span>列，取值范围<span class="math inline">\(\{0,1,-k\}\)</span>，0表示该样本对第<span class="math inline">\(j\)</span>个类的梯度没有贡献（该样本标签不是<span class="math inline">\(j\)</span>且不满足指示函数），1表示贡献了<span class="math inline">\(x_i\)</span>（该样本标签不是<span class="math inline">\(j\)</span>且满足指示函数），<span class="math inline">\(-k\)</span>表示贡献了<span class="math inline">\(-kx_i\)</span>（该样本的标签就是<span class="math inline">\(j\)</span>），因此：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dW = np.dot(X.T, margins) / num_train + <span class="number">2</span> * reg * W</span><br></pre></td></tr></table></figure>
<p>可以从矩阵维度相容的角度验证。 ## Softmax 先用循环实现一个<code>softmax_loss_naive(W, X, y, reg)</code>，输入的shape和SVM相同。 softmax分类器不再将<span class="math inline">\(f(x_i;W)\)</span>看做每个类的得分，而是希望输出normalized class probabilities，最终选一个概率最大的类作为预测，<strong>softmax函数</strong>就能将<span class="math inline">\(f(x_i;W)\)</span>映射到<span class="math inline">\([0,1]\)</span>且满足概率的性质： <span class="math display">\[P(y_i \mid x_i; W) = \frac{e^{f_{y_i}}}{\sum_j e^{f_j} }\]</span> 从预测函数可以看到：softmax是把<span class="math inline">\(f(x_i;W)\)</span>看作unnormalized log probabilities，因此对<span class="math inline">\(f(x_i;W)\)</span>先指数再归一化得到每个类的概率。</p>
<p>再来看softmax的损失函数： <span class="math display">\[L_i = -\log\left(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} }\right) \hspace{0.1in} \text{or equivalently} \hspace{0.1in} L_i = -f_{y_i} + \log\sum_j e^{f_j}\]</span> 从直觉上说：属于正确类<span class="math inline">\(y_i\)</span>的概率（括号里的分式）越高，损失应该越小，这就是大名鼎鼎的<strong>cross-entropy loss</strong>，衡量了真实分布<span class="math inline">\(p\)</span>和预测分布<span class="math inline">\(q\)</span>之间的差距： <span class="math display">\[H(p,q) = - \sum_x p(x) \log q(x)= H(p) + D_{KL}(p||q)\]</span> 具体到softmax： <span class="math display">\[q=\frac{e^{f_{y_i}}}{ \sum_j e^{f_j} },p = [0, \ldots 1, \ldots, 0]\]</span> 其中，<span class="math inline">\(p\)</span>在第<span class="math inline">\(y_i\)</span>个位置上为1。 由于<span class="math inline">\(H(p)=0\)</span>，因此其实是在最小化<span class="math inline">\(p\)</span>和<span class="math inline">\(q\)</span>的KL散度，即希望预测结果<span class="math inline">\(q\)</span>尽量向<span class="math inline">\(p\)</span>靠近。</p>
<p>从概率的角度出发看损失函数，我们是在最小化正确类<span class="math inline">\(y_i\)</span>的负对数似然，本质上就是在做一个极大似然估计。</p>
<p>看完理论，还要考虑一些现实问题。比如数值稳定性，由于指数的原因可能会导致overflow或者underflow，因此做一个简单的等价变换： <span class="math display">\[\frac{e^{f_{y_i}}}{\sum_j e^{f_j}}
= \frac{Ce^{f_{y_i}}}{C\sum_j e^{f_j}}
= \frac{e^{f_{y_i} + \log C}}{\sum_j e^{f_j + \log C}}\]</span> 一般选<span class="math inline">\(\log C = -\max_j f_j\)</span>，这个变换不会改变预测函数或者损失函数，只是将得分做了平移。</p>
<p>至此，naive版本的loss就基本有了，接着看看梯度咋求。先稍稍展开康康： <span class="math display">\[L_i=-f_{y_i} + \log\sum_j e^{f_j}=-w_{y_i}^Tx_i+log\sum_je^{w_j^Tx_i}\]</span> 其中，<span class="math inline">\(w_j\)</span>表示W的第<span class="math inline">\(j\)</span>列。 然后使用我们的小学数学知识去求偏导： <span class="math display">\[\nabla_{w_{y_i}} L_i =(\frac{e^{f_{y_i}}}{ \sum_j e^{f_j}}-1)x_i \\
\nabla_{w_j} L_i = \frac{e^{f_{j}}}{ \sum_j e^{f_j}}x_i\]</span> 记<code>p = np.exp(scores) / np.sum(np.exp(scores))</code>，shape为<span class="math inline">\((C,)\)</span>，表示样本<span class="math inline">\(i\)</span>属于每个类的概率。 所以<code>dW</code>的第<code>y[i]</code>列更新即为<code>(p[y[i]] - 1) * X[i]</code>，其他列更新为<code>p[j] * X[i]</code>。</p>
<p>接着看下vectorized版本，<code>scores</code>的shape变为了<span class="math inline">\((N,C)\)</span>，首先处理数值稳定性问题，每一行都减去该行的最大值（注意<code>keepdim=True</code>）；接着求出概率矩阵<code>p</code>，shape与<code>scores</code>相同，那么loss为： <code>loss = np.sum(-np.log(p[np.arange(X.shape[0]), y])) / X.shape[0]</code> 与SVM类似，<code>dW</code>的每一列（每个类）是由每个训练样本影响的线性组合决定的，组合系数取决于该训练样例的标签，比如对于<code>dW</code>的第<span class="math inline">\(j\)</span>个类来说，如果某个样例的标签恰好是<span class="math inline">\(j\)</span>，那么其对梯度的贡献就是<code>p[j]-1</code>，否则系数就是<code>p[j]</code>。因此只要将概率矩阵<code>p</code>中所有正确标签的值减1即得到系数矩阵，进而得到<code>dW</code>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">p[np.arange(X.shape[<span class="number">0</span>]), y] = p[np.arange(X.shape[<span class="number">0</span>]), y] - <span class="number">1</span></span><br><span class="line">dW = np.dot(X.T, p)</span><br></pre></td></tr></table></figure>
<p>同样可以用维度相容去check。 ## Neural Network 这是一个两层的全连接神经网络，架构如下： 输入<span class="math inline">\((N,D)\)</span>-&gt;全连接层1-&gt;ReLU-&gt;全连接层2（输出每个类的得分）-&gt;softmax 参数们的shape为：<span class="math inline">\(X(N,D),W1(D,H),b1(H,),W2(H,C),b2(C,)\)</span></p>
<p>第一步Forward Pass，根据输入X和权值W计算<span class="math inline">\(scores(N,C)\)</span>，然后计算softmax loss； 第二步Backward Pass，需要计算loss对于参数们的梯度，根据网络结构： <span class="math display">\[h=XW1+b1\\
o=ReLU(h)\\
s=oW2+b2\\
L=\sum_i(-s_{y_i}+log\sum_j e^{s_j})\]</span> 根据链式法则+维度相容： <span class="math display">\[\nabla_{w_2} L =o^T \nabla_{s} L\\
\nabla_{b_2} L =(\nabla_{s} L)^T(\nabla_{b_2} s)=(C,N)(N,1)=(C,N)(all\ 1\ col)\\
\nabla_{w_1} L =X^T \nabla_{s} L\nabla_{h} s\\
\nabla_{b_1} L =\nabla_{h} s (\nabla_{s} L)^T\nabla_{b_1} h=(H,C)(C,N)(N,1)=(H,C)(C,N)(all\ 1\ col)\]</span> 可以看出：关键在于求出<span class="math inline">\(\nabla_{s} L\)</span>，在对softmax的讨论中可知，对于第<span class="math inline">\(y_i\)</span>列导数为<code>p[y[i]]-1</code>，对其他列为<code>p[j]</code>，因此该偏导为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">d2 = p</span><br><span class="line">d2[np.arange(X.shape[<span class="number">0</span>]), y] -= <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p>另外对于<span class="math inline">\(W_1,b_1\)</span>，还需要<span class="math inline">\(\nabla_{h} s\)</span>：这玩意在<span class="math inline">\(h&gt;0\)</span>就是<span class="math inline">\(W_2^T\)</span>，否则就是0。因此<span class="math inline">\(\nabla_{s} L\nabla_{h} s\)</span>可以写为：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">d1 = d2.dot(W2.T) * (h &gt; <span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<h2 id="image-features">Image Features</h2>
<p>之前的样例都是直接用raw pixel，加上都是线性模型，效果拉跨太正常了。这里用的人工feature包括HOG(Histogram of Oriented Gradients)和color histogram，HOG捕捉texture（纹理变化？）信息，color histogram捕捉颜色信息，两者互相辅助。&lt;/c$&gt;</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/07/17/1171%20Remove%20Zero%20Sum%20Consecutive%20Nodes%20from%20Linked%20List/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/17/1171%20Remove%20Zero%20Sum%20Consecutive%20Nodes%20from%20Linked%20List/" class="post-title-link" itemprop="url">1171 Remove Zero Sum Consecutive Nodes from Linked List</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-07-17 06:50:00" itemprop="dateCreated datePublished" datetime="2021-07-17T06:50:00+08:00">2021-07-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p><a target="_blank" rel="noopener" href="https://leetcode.com/problems/remove-zero-sum-consecutive-nodes-from-linked-list/">题目链接</a> ## 题意 给定一个单链表，删除和为0的连续结点序列，直到最终链表中没有和为0的连续结点序列。 样例：head = [1,2,3,-3,-2]，输出[1] ## 分析 由于链表头结点可能会被删除，因此首先创建dummy结点。一个比较直观的想法就是记录前缀和，依次遍历链表，遇到出现过的前缀和也就意味着出现了和为0的序列，就删除两次相同前缀和中间的序列。因此需要一个hashtable记录前缀和出现的位置，手动走一个简单样例吧： dummy设为<code>(0,head)</code>，hashtable初始包含<code>&#123;0:dummy&#125;</code>，避免[1,-1]这种情况。</p>
<ol type="1">
<li><code>cur=p(1),sum=1,hash=&#123;0:dummy,1:p(1)&#125;</code></li>
<li><code>cur=p(2),sum=3,hash=&#123;0:dummy,1:p(1),3:p(2)&#125;</code></li>
<li><code>cur=p(3),sum=6,hash=&#123;0:dummy,1:p(1),3:p(2),6:p(3)&#125;</code></li>
<li><code>cur=p(-3),sum=3</code>：此时hash返回p(2)，因此就让p(2).next指向cur.next，相当于删除了[3,-3]，<code>hash=&#123;0:dummy,1:p(1),3:p(2),6:p(3)&#125;</code></li>
<li><code>cur=p(-2),sum=1</code>：此时hash返回p(1)，因此让p(1).next指向cur.next，相当于删除了[2,-2]，<code>hash=&#123;0:dummy,1:p(1),3:p(2),6:p(3)&#125;</code></li>
</ol>
<p>大概可以写出这样的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeZeroSumSublists</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        dummy = ListNode(<span class="built_in">next</span>=head)</span><br><span class="line">        cur = head</span><br><span class="line">        prefix_sum = <span class="number">0</span></span><br><span class="line">        hashtable = &#123;<span class="number">0</span>:dummy&#125;</span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            prefix_sum += cur.val</span><br><span class="line">            p = hashtable.get(prefix_sum)</span><br><span class="line">            <span class="keyword">if</span> p:</span><br><span class="line">                p.<span class="built_in">next</span> = cur.<span class="built_in">next</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                hashtable[prefix_sum] = cur</span><br><span class="line">            cur = cur.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<p>交上去WA了，问题出在哪呢？ 走一遍出错的样例：输入[1,3,2,-3,-2,5,5,-5,1]，期待[1,5,1]，输出[1,5,5,-5,1]</p>
<ol type="1">
<li><code>cur=p(1),sum=1,hash=&#123;0:dummy,1:p(1)&#125;</code></li>
<li><code>cur=p(3),sum=4,hash=&#123;0:dummy,1:p(1),4:p(3)&#125;</code></li>
<li><code>cur=p(2),sum=6,hash=&#123;0:dummy,1:p(1),4:p(3),6:p(2)&#125;</code></li>
<li><code>cur=p(-3),sum=3,hash=&#123;0:dummy,1:p(1),4:p(3),6:p(2),3:p(-3)&#125;</code></li>
<li><code>cur=p(-2),sum=1</code>：此时hash返回p(1)，让p(1).next指向p(-2).next，链表变为了[1,5,5,-5,1]，<code>hash=&#123;0:dummy,1:p(1),4:p(3),6:p(2),3:p(-3)&#125;</code></li>
<li><code>cur=p(5),sum=6</code>：此时hash返回p(2)，但此时p(2)已经删除，因此让p(2).next指向p(5).next肯定是错的。</li>
</ol>
<p>至此应该可以看出问题了：在删除改变链表指针的同时，hashtable并没有做相应的同步删掉对应的元素，所以每当出现重复前缀和时只要删掉hashtable中两次前缀和之间的项即可，可以借助<code>OrderedDict()</code>实现，按照插入顺序即链表顺序有序：</p>
<ol type="1">
<li><code>cur=p(-3),sum=3,hash=&#123;0:dummy,1:p(1),4:p(3),6:p(2),3:p(-3)&#125;</code></li>
<li><code>cur=p(-2),sum=1</code>：此时hash(1)返回p(1)，删除后为<code>hash=&#123;0:dummy,1:p(1)</code></li>
<li><code>cur=p(5),sum=6</code>：此时hash返回<code>None</code>，符合预期，继续迭代即可。</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeZeroSumSublists</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        dummy = ListNode(<span class="built_in">next</span>=head)</span><br><span class="line">        cur = head</span><br><span class="line">        prefix_sum = <span class="number">0</span></span><br><span class="line">        hashtable = OrderedDict(&#123;<span class="number">0</span>:dummy&#125;)</span><br><span class="line">        <span class="keyword">while</span> cur:</span><br><span class="line">            prefix_sum += cur.val</span><br><span class="line">            prev = hashtable.get(prefix_sum, cur)</span><br><span class="line">            <span class="keyword">while</span> prefix_sum <span class="keyword">in</span> hashtable:</span><br><span class="line">                hashtable.popitem()</span><br><span class="line">            hashtable[prefix_sum] = prev</span><br><span class="line">            prev.<span class="built_in">next</span> = cur = cur.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<p>Two-pass： 上述做法的hashtable记录的是第一次出现前缀和的位置。现在换一种思路：首先遍历一次链表，hashtable记录<strong>最后一次</strong>出现前缀和的位置，第二次遍历链表设置相应的指针到最后一次前缀和的位置，这样即使第一次前缀和位置被删除，指针也会相应地跳过：</p>
<ol type="1">
<li>第一次遍历后：<code>hash=&#123;0:dummy,1:p(-2),4:p(3),6:p(-5),3:p(-3),11:p(5),7:p(1)&#125;</code></li>
<li>第二次遍历：<code>dummy.next=hash[0].next,p(1).next=hash[1].next=p(5),p(5).next=hash[6].next=p(1),p(1).next=hash[7].next=null</code></li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Definition for singly-linked list.</span></span><br><span class="line"><span class="comment"># class ListNode:</span></span><br><span class="line"><span class="comment">#     def __init__(self, val=0, next=None):</span></span><br><span class="line"><span class="comment">#         self.val = val</span></span><br><span class="line"><span class="comment">#         self.next = next</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Solution</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">removeZeroSumSublists</span>(<span class="params">self, head: ListNode</span>) -&gt; ListNode:</span></span><br><span class="line">        dummy = ListNode(<span class="number">0</span>, head)</span><br><span class="line">        prefix_sum = <span class="number">0</span></span><br><span class="line">        hashtable = &#123;<span class="number">0</span>:dummy&#125;</span><br><span class="line">        <span class="keyword">while</span> head:</span><br><span class="line">            prefix_sum += head.val</span><br><span class="line">            hashtable[prefix_sum] = head</span><br><span class="line">            head = head.<span class="built_in">next</span></span><br><span class="line">            </span><br><span class="line">        prefix_sum = <span class="number">0</span></span><br><span class="line">        head = dummy</span><br><span class="line">        <span class="keyword">while</span> head:</span><br><span class="line">            prefix_sum += head.val</span><br><span class="line">            head.<span class="built_in">next</span> = hashtable[prefix_sum].<span class="built_in">next</span></span><br><span class="line">            head = head.<span class="built_in">next</span></span><br><span class="line">        <span class="keyword">return</span> dummy.<span class="built_in">next</span></span><br></pre></td></tr></table></figure>
<p>时间复杂度<span class="math inline">\(O(n)\)</span>，空间复杂度<span class="math inline">\(O(n)\)</span>。</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/07/15/Research%20Proposal/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/15/Research%20Proposal/" class="post-title-link" itemprop="url">Research Proposal</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-07-15 02:35:00" itemprop="dateCreated datePublished" datetime="2021-07-15T02:35:00+08:00">2021-07-15</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="时间节点">时间节点</h2>
<ol type="1">
<li>开题答辩：11月20第一批，1.1第二批</li>
<li>实习：1.1第一批，3.1第二批</li>
<li>自身安排：第一批开题并且第一批出去。 从9.25~12.31全力科研，完成创新点2，并且写成毕业论文的格式；零碎时间自学提升。 2022.1.1~2022.7.1全部用来实习。</li>
</ol>
<h2 id="创新点1">创新点1</h2>
<ol type="1">
<li>加入了采样方法的自动选择</li>
<li>代理模型对于高维稀疏数据的处理XGBoost</li>
<li>Playout阶段的改进</li>
</ol>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
代理模型采用二分类器，类似于FB的paper</li>
<li><input type="checkbox" disabled="" />
pipeline：默认config组成的pipeline的影响（结合meta-learning）；components在Tree中的层次搜索顺序：初始数据集均匀随机采3个，嵌入先验分布，如<code>score_each_cl</code>通过先验进行修正</li>
</ul>
<h2 id="创新点2">创新点2</h2>
<ol type="1">
<li>搜索过程产生的config按某种策略（动态推荐）做ensemble</li>
<li>评价指标换用其它综合指标，避免recall/precision等简单指标（接近极限了）。换指标的话就可以用KEEL和Imblearn的大部分数据集，不用去找其他的或者用少数类数目筛选</li>
</ol>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
建立不平衡数据集的meta database作为warm-start，加速搜索过程</li>
<li><input type="checkbox" disabled="" />
使用bandit等策略来对时间分配策略调整</li>
<li><input type="checkbox" disabled="" />
考虑从黑盒优化转为灰盒优化（Multi-fidelity优化），如训练集子集、观察学习曲线等</li>
<li><input type="checkbox" disabled="" />
朱老师说的按照元特征去指导MCTS的搜索方向，提前剪枝等</li>
<li><input type="checkbox" disabled="" />
多分类不平衡数据</li>
</ul>
<h2 id="探索">探索</h2>
<ul class="task-list">
<li><input type="checkbox" disabled="" />
AdaBoost/AdaBoost-MH/GBDT/XGBoost/LightGBM（工业界用的多）等集成学习用来对分错的数据集进行提升</li>
<li><input type="checkbox" disabled="" />
概率图模型（每个数据集对应的可能的算法是由概率形式表现的）：<span class="math inline">\(P(A_i|D)=\cfrac{P(D|A_i)P(A_i)}{P(D)}\)</span></li>
<li><input type="checkbox" disabled="" />
BO/CBO/SOO (综述paper)</li>
<li><input type="checkbox" disabled="" />
除了基于精确度和时间的对比，但是很多时候搜索阶段表现最好的，在评估阶段并不是最好的，甚至可能表现很差。 因此一种用的比较多的就是Kendall Tau metric，它会评估两个阶段模型性能的相关性，相关性越高则表示算法越有效</li>
<li><input type="checkbox" disabled="" />
<strong>多样本</strong>：图神经网络==深度学习链接预测</li>
</ul>
<p>可能由于样本量太少，特征太多，导致数据稀疏，用低维特征去做分类，元特征选择/降维</p>
<p>致命缺点：算法性能的差别可能是由于数据集质量决定的，而不是元特征的质量？？所以元特征还应有一个衡量数据集质量的特征？？</p>
<h2 id="advice">Advice</h2>
<ul>
<li>现有方法软肋，针对性idea稳妥。论文要多问<strong>为什么</strong>，为什么用这个模型，为什么在这种数据上表现好...</li>
<li>读AutoML</li>
</ul>
<ol type="1">
<li>我要解决的问题是什么？</li>
<li>这个问题的难点在哪？</li>
<li>别人是怎么干的？为什么这么干？效果怎么样？这么干有什么缺陷？</li>
<li>我打算怎么干？为什么这样干是对的？</li>
<li>实验验证 ## Next</li>
<li>小数据集、GNN(Graphsage/pinsage/gat，GCN/Deepwalk不能用)、新特征表示、KNN 每次来一个新的测试数据集，就加入图中，动态增长变化的模型</li>
<li>大数据集、GraphSage/DNN变为多标签分类{A1 A2...}</li>
<li>DRL</li>
</ol>
<h2 id="tricks">Tricks</h2>
<ul>
<li>更改UCI问题数据集</li>
<li>看看最终的元模型在哪些数据集表现不佳，适当替换数据集</li>
</ul>
<h2 id="now">Now</h2>
<ol type="1">
<li>对于不平衡数据集，需要采样进行预处理，推荐合适的采样的算法及其超参数（采样比例等）</li>
<li>GNN对原始数据集提特征，要求数据集特征数目相同，可能要降维等</li>
</ol>
<h2 id="图神经网络">图神经网络</h2>
<p>图神经网络商品推荐非常准确：用户和产品间的交互 <img src="https://img-blog.csdnimg.cn/20210117170914563.png" alt="在这里插入图片描述" /></p>
<ul>
<li>图卷积网络GCN</li>
<li>图注意力网络GAN</li>
<li>图自编码器</li>
<li>图生成网络</li>
<li>图时空网络</li>
</ul>
<p>图结构信息：经典的DNN、RNN、CNN处理效果不好</p>
<p>社交网络（用户、关系） 电子购物（用户、商品） 化学分子（原子、化学键）</p>
<p>多标签的GNN？异构图的GNN？</p>
<p>数据：MultiKNN那篇文章生成数据集的方法</p>
<p>欧几里得数据：图像、文本、视频</p>
<p>ML假设样本独立，图数据不满足 <img src="https://img-blog.csdnimg.cn/20210118155146919.png" alt="在这里插入图片描述" /> 网络嵌入：保留网络拓扑架构和结点内容信息，将网络顶点表示到低维向量空间，使得后续的分类、聚类、推荐使用简单的算法即可完成：</p>
<ul>
<li>矩阵分解</li>
<li>随机游走</li>
<li>深度学习：同时属于GNN</li>
</ul>
<figure>
<img src="https://img-blog.csdnimg.cn/20210118185948765.png" alt="" /><figcaption>在这里插入图片描述</figcaption>
</figure>
<p>抽特征后，新的数据集可能和历史数据集有联系，即和图中的某些结点有带权边，可以用GCN从邻域聚合特征信息。</p>
<ul>
<li>GCN：</li>
<li>图注意力网络：重要的结点会有更大的权值，在聚合特征信息时向不同近邻分配注意力权重、根据注意力权重集成多个模型，以及使用注意力权重引导随机游走</li>
</ul>
<p>传统深度学习加层会带来效果的提升，但是研究表明：图网络随着层数增加，性能急剧下降； 不能扩展到大型图；</p>
<h2 id="graph-embedding">Graph embedding</h2>
<p>发现高维图的低维向量表示 <img src="https://img-blog.csdnimg.cn/20210119101906372.png" alt="在这里插入图片描述" /></p>
<p>异构图GNN，算法结点的特征空间可以考虑算法本身的性质等？</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/07/14/%E5%85%B3%E4%BA%8E%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95%E7%9A%84%E8%80%83%E8%99%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/14/%E5%85%B3%E4%BA%8E%E8%81%8C%E4%B8%9A%E5%8F%91%E5%B1%95%E7%9A%84%E8%80%83%E8%99%91/" class="post-title-link" itemprop="url">关于职业发展的考虑</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-07-14 03:22:00" itemprop="dateCreated datePublished" datetime="2021-07-14T03:22:00+08:00">2021-07-14</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <p>事情缘由是这样的：自从二战以后，我个人对未来职业上的事就淡然处之了，更加关注生活方面的幸福感，这其实也没有太大的过错，而且我自己感觉这些时间总体上还是越来越happier了。</p>
<p>前段时间有好朋友拿到Google Seattle的offer，又有朋友要去UCSD追寻学术梦想了，再想想许多朋友都在国外混得风生水起，觉得自己也不能太咸鱼吧，我自己清楚这并不是与别人比较，而是在基本物质得不到满足的情况下，未来的现实生活并没有想象中的那么ideal，尤其是我这种条件。</p>
<p>所以我希望更加细化自己的职业规划，并且结合当前的现实情况制定下一步的具体措施。</p>
<ol type="1">
<li>重视思想认识 一方面，要足够重视找工作对未来生活的影响，可以适当牺牲一些当前生活的幸福指数；另一方面，要深刻认识到时间并不充裕，满打满算也就一年，尤其自己还是没什么天赋的非科班选手。 High expectation并不会带来太大的失望，learn to fail or fail to learn。 在不把自己限制死的前提下，目前大的方向就是去互联网（包括银行、国企、fin-tech）或者去高中教师。</li>
<li>分析现实情况 2.1 实验室：首先就是认清目前的境遇：在这个学校的当前这个实验室靠发顶会论文找到好工作的可能几乎没有，因此只能通过自学和实习来增加找到好工作的几率；老师的目标和自身目标在某些方面是一致的（如毕业），但是在很多方面是有很大冲突的（老师希望发好文章保住饭碗或者干项目，我希望用更多时间去准备工作），所以不能一味听从老师的忽悠，不要把注意力过于放在老师身上，要有自己清醒的判断：你最终找到什么样的工作老师压根不会关心，他们只会抢你的一作。另外，不必太过担心毕业的事情，按照自身的水平和XJTU的尿性，正常毕业应该问题不太大。 2.2 博士：不要被周围的博士蒙蔽，我自己暂时绝没有读博的打算，因此在科研问题上没必要较真，平时的讨论也要注意自己的定位。而且从目前来看：周围环境下的博士做的也基本是垃圾。当然并不排除工作几年后出国读博/国内优秀导师读博的可能性，虽然目前来看这种可能性并不大。 2.3 工作（努力）方向：高中教师包括数学和计算机的可能性，计算机的教资要尽快拿到，到时候找工作可以直接去面试，这一点可以作为备选方案，届时进行offer比较； 互联网的方向就是算法和开发：首先自身暂时倾向于算法岗，找实习/工作时如果过于困难就转开发。开发这边目前已经积累了一些项目，但仍有很多薄弱点（如java）；算法目前没有项目，要迅速找一些<strong>较大</strong>的项目/比赛完成，同时还要打磨自己开发上的积累，<strong>如此看来时间更加紧迫</strong>。 目标就是能拿到微软或者国内大厂sp这一档的offer。</li>
<li>具体措施 3.1 hard work：不论是各位前辈还是哈佛的课都在强调这点，这同时也意味着要减少不必要的娱乐时间（看b站、大量外出吃饭唱歌等），当然这并不意味着不锻炼或者低效学习，而是要增加高效学习的时间。 3.2 科研与自学的平衡：科研只要达到外出实习和毕业的最低要求就行，不要太较真，抱着差不多就行了的态度，不要想着做出顶会级的成果，<strong>但是首先要集中精力水出一篇垃圾以获得外出实习的机会</strong>；自学一定要足够敬畏和认真，扎扎实实推进。 3.3 自学：这方面的具体措施已经写在博客里，不再赘述。</li>
</ol>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/07/10/Optimization%20Methods%20in%20Deep%20Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/07/10/Optimization%20Methods%20in%20Deep%20Learning/" class="post-title-link" itemprop="url">Optimization Methods in Deep Learning</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-07-10 11:47:00" itemprop="dateCreated datePublished" datetime="2021-07-10T11:47:00+08:00">2021-07-10</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="background">Background</h2>
<p>深度神经网络的训练过程主要通过求解一个特定的优化问题来实现，然而由于该问题是一个复杂的高维非线性优化问题，并且不同的网络结构差异很大，不能将传统的优化方法直接使用。即使数据集和网络结构完全相同，不同的优化算法也可能导致完全不同的收敛效果。实际应用的一些简单方法虽然行之有效，但现有理论无法充分解释其有效性，超参数的不断增加也给优化增加了不少难度。如何确保算法收敛、如何尽快收敛以及能否收敛到全局最优一直是困扰学术界和工业界的问题。如果能够用优化理论去解释神经网络的训练行为，对于深度学习的推广应用将会起到巨大的推动作用。</p>
<p>对于有监督学习，给定包含n个样本的训练集<span class="math inline">\(\{(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n)\}\)</span>，<span class="math inline">\(\mathbf{x}\)</span>表示样本的特征向量，<span class="math inline">\(y\)</span>表示该样本对应的标签。我们的任务是利用样本信息来预测相应的标签，使预测值尽可能接近真实标签。如果用深度学习来完成这个任务，就需要通过调整神经网络的参数（权重W和偏差b）来近似数据背后的函数映射关系，这个关系往往是高度非线性的，网络越深表达能力也就越强，逼近效果的精度也就更高，因此网络结构很可能是极其复杂的。</p>
<p>为了衡量预测值和真实值之间的接近程度，通常需要采用某种距离度量方式<span class="math inline">\(l\)</span>，<span class="math inline">\(l\)</span>一般设计为<strong>可微</strong>的，接着用一些优化算法去最小化该目标函数。因此优化问题变为寻找最佳的参数使得<span class="math inline">\(l\)</span>最小，在不考虑正则项的情况下有： <span class="math display">\[
\mathop{\mathrm{min}}_f \frac{1}{n} \sum_{i=1}^n l(f(\mathbf{x}_i), y_i)
\]</span> <span class="math inline">\(f\)</span>就是我们从输入到输出的映射函数，<span class="math inline">\(l\)</span>通常也叫损失函数，衡量预测值<span class="math inline">\(f(x_i)\)</span>和真实标签<span class="math inline">\(y_i\)</span>的差距，比如回归问题中经常使用的平方损失函数<span class="math inline">\(l=||f(x_i)-y_i||^2\)</span>。</p>
<p>需要注意的是：深度学习中的优化问题与传统意义上的优化问题有所差别。传统的优化问题需要尽可能找到目标函数的最值，而深度学习的最终目的是为了<strong>预测未知</strong>的数据，而不是将训练数据上的损失降到最低。我们定义的损失函数<span class="math inline">\(J(\Theta)\)</span>衡量的是当前模型参数<span class="math inline">\(\Theta\)</span>在<strong>训练集</strong>上的优劣，然而，最小化训练误差并不意味着模型的泛化误差也会最小，为了降低泛化误差我们还需要关注过拟合问题，因此损失函数往往要加上<strong>正则项</strong>。统计学上称为经验风险最小化，即由于无法获得全部数据，所以只能用经验风险作为实际风险的近似。非常有意思的是：尽管大多数神经网络都是严重过参数化的，但是反而有着比较不错的泛化能力，这与传统的机器学习观点是矛盾的，泛化理论也需要更加深入的研究。</p>
<p>深度学习中的<span class="math inline">\(f\)</span>通常是多层的复合函数，由于太复杂而无法求出解析解，所以要用数值优化算法去求解。实际中主流的深度学习优化算法都利用梯度下降来求解，梯度下降是深度学习优化算法的基础，尽管目前已经很少直接使用，但它却是其他高级优化算法的基石： 假设网络的参数为<span class="math inline">\(x=(x_1,x_2,...,x_d)^T\)</span>，优化的目标函数为<span class="math inline">\(f\)</span>，那么<span class="math inline">\(f\)</span>的梯度为： <span class="math display">\[
\nabla f(\mathbf{x}) = \bigg[\frac{\partial f(\mathbf{x})}{\partial x_1}, \frac{\partial f(\mathbf{x})}{\partial x_2}, \ldots, \frac{\partial f(\mathbf{x})}{\partial x_d}\bigg]^\top
\]</span> 每个元素对应着目标函数在该方向上的变化率，因此只要沿着梯度的反方向就可以使目标函数减小得最快：<span class="math inline">\(\mathbf{x} \leftarrow \mathbf{x} - \eta \nabla f(\mathbf{x})\)</span>，<span class="math inline">\(\eta\)</span>是一个被称为学习率的超参数，用来控制每一步的大小。<span class="math inline">\(\eta\)</span>过小，收敛过程极度缓慢；<span class="math inline">\(\eta\)</span>过大，可能造成损失函数在最小点附近波动甚至发散。学习率的调整是神经网络训练过程中一个重要的调整参数，常常使人头痛不已，因此也出现了很多学习率自适应调整的算法，将在下面深入分析这些算法的优劣。</p>
<p>有了优化模型及最基础的求解方法后，我们需要对其性质和优缺点进行分析，以便于后续的改进。深度学习的优化问题大多是非凸的，因此存在很多挑战：</p>
<ol type="1">
<li>局部最优：对于凸优化问题，局部最优即是全局最优。然而对于非凸问题，当损失函数到达局部最优点时，<span class="math inline">\(J(\Theta)\)</span>的梯度为0，<span class="math inline">\(\Theta\)</span>无法继续更新，损失函数无法继续下降；</li>
<li>鞍点：该点既不是局部最小也不是全局最小，但是该点的梯度消失，无法继续更新；</li>
<li>梯度消失/爆炸：由于初始值和激活函数选择不当 (如sigmoid)，当梯度反向回传时，可能在某一层求导后梯度值很小/很大，导致训练速度极其缓慢。因此初始值的选择通常采用很小的随机数，避免收敛到比较差的区域，激活函数通常也会选择ReLU，避免梯度消失问题。</li>
</ol>
<p>局部最小和鞍点示意图如下： <img src="https://img-blog.csdnimg.cn/20210710191530881.png" alt="在这里插入图片描述" /> 尤其在高维空间中，鞍点的问题变得更加严重：假设<span class="math inline">\(\Theta\)</span>是一个k维向量，<span class="math inline">\(J(\Theta)\)</span>的海森矩阵就有k个特征值，其梯度为0的点有可能是局部最小（特征值均为正）、局部最大（特征值均为负）或者是鞍点（特征值有正有负）。高维空间中特征值有正有负的概率很大，因此鞍点出现的可能性远大于局部最优点出现的可能性，并且鞍点周围的平坦区域可能很大，需要增加噪声扰动来逃离鞍点。</p>
<p>由于上述问题的存在，通常很难找到<span class="math inline">\(J(\Theta)\)</span>的全局最优解，但实际上为了减少过拟合的风险我们并不需要训练集上的全局最优，经典的梯度下降就可以带来足够的局部最优。</p>
<p>分析完优化模型本身的问题，再来看看最基础的GD的问题：目标函数通常是训练集中所有样本的损失的平均值，故目标函数的梯度为： <span class="math display">\[
\nabla f(\mathbf{x}) = \frac{1}{n} \sum_{i = 1}^n \nabla f_i(\mathbf{x})
\]</span> 如果用Full-batch GD，那么每次迭代每个参数的梯度计算的时间复杂度为<span class="math inline">\(O(n)\)</span>，对于大规模数据，这样的更新速度显然无法令人忍受。</p>
<p>学习率的选择是一项重要的调参工作，因此学习率的自适应变化就成为了研究热点之一，一些二阶方法应运而生，我们首先来看看牛顿法该如何解决这个问题。</p>
<p>对于损失函数<span class="math inline">\(f\)</span>，利用泰勒展开式有： <span class="math display">\[
f(\mathbf{x} + \boldsymbol{\epsilon}) = f(\mathbf{x}) + \boldsymbol{\epsilon}^\top \nabla f(\mathbf{x}) + \frac{1}{2} \boldsymbol{\epsilon}^\top \nabla^2 f(\mathbf{x}) \boldsymbol{\epsilon} + \mathcal{O}(\|\boldsymbol{\epsilon}\|^3)
\]</span> 式中的<span class="math inline">\(\nabla^2 f(\mathbf{x})\)</span>即<span class="math inline">\(d*d\)</span>海森矩阵，存储了函数的二阶偏导数。为了求得<span class="math inline">\(f\)</span>的最小值，令上式对<span class="math inline">\(\epsilon\)</span>求导得0，有：<span class="math inline">\(\boldsymbol{\epsilon}=-\nabla f(\mathbf{x})H^{-1}\)</span>，即每次的参数更新为<span class="math inline">\(\mathbf{x} \leftarrow \mathbf{x} - \nabla f(\mathbf{x})H^{-1}\)</span>。二阶近似利用了损失函数的曲率信息，即如果曲率比较小，那么这步更新就会比较大，反之则更新较小。这里没有了学习率，而是通过“梯度的梯度”自动调整步幅，看起来比一阶的梯度下降要好一些。</p>
<p>然而深度学习的参数空间往往十分巨大，因此存储和计算海森矩阵的逆是不现实的，这也是牛顿法无法在DNN中使用的重要原因。为了缓解这个问题，学术界提出了一些拟牛顿法如L-BFGS等试图去降低存储消耗，但是计算代价仍然很高。</p>
<p>从以上的分析可以看到：无论是Full-batch GD还是牛顿法，都存在计算消耗大等问题，不适用于深度学习任务的大规模数据集训练，因此已经很少被直接用在深度学习模型中。为了处理这些问题，学术界提出了很多替代的优化算法，因此接下来我将调研分析当前常用的深度学习优化算法 (SGD/Adam...)的优缺点，并结合实例及前沿研究进行相关讨论。 ## Popular Algorithms 优化算法在神经网络的训练中有着举足轻重的作用，选择合适的优化算法可以使得损失函数收敛地更快，同时收敛到更好的区域。目前比较流行的算法有下面几种： ### 1 SGD 尝试用mini-batch的梯度平均值作为整体梯度的无偏估计，参数的更新非常简单，沿着梯度的反方向即是loss下降最快的方向： <span class="math display">\[
x_{t+1}=x_t-\alpha\nabla f(x_t)
\]</span> 如果是Batch GD并且学习率足够小时可以保证损失函数单调不增。实际使用时一般会采用学习率递减策略保证模型收敛。</p>
<p>实现也非常简单：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">x -= lr * grads</span><br></pre></td></tr></table></figure>
<p>SGD存在几个问题：</p>
<p>首先，如果loss对于不同参数的敏感程度不同，那么收敛过程会在敏感参数方向上抖动： <img src="https://img-blog.csdnimg.cn/20210710192205509.png" /> 对于非常大的参数空间，可能会收敛到不同的区域。 其次，如果loss函数有局部最优或者鞍点，这些点上梯度为0，无法收敛到全局最优； 最后，如果采用mini-batch，那么计算出的梯度值是有噪声的，意味着收敛过程可能会是非常曲折的，也即需要更多时间。 ### 2 SGD+Momentum 为了解决SGD的问题，有学者提出了带有动量的SGD，其思想也很简单：更新参数时不仅考虑当前的梯度方向，还要考虑历史累积梯度方向，如果两者方向一致，那么这一步更新幅度就会增大；如果不一致，就会减弱沿当前梯度的下降幅度。 <span class="math display">\[
v_{t+1}=\rho v_t+\nabla f(x_t) \\
x_{t+1}=x_t-\alpha v_{t+1}
\]</span> <span class="math inline">\(\rho\)</span>可以看作是对历史梯度的衰减，一般取0.9。</p>
<p>带有动量的SGD实现： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">v = rho * v + grads</span><br><span class="line">x -= lr * v</span><br></pre></td></tr></table></figure> 这样就解决了SGD的三个问题： 首先，由于历史梯度的存在，朝敏感方向步进的数量就会减少，会更加平滑的向最优点前进，减小了震荡，加速收敛； 其次，对于局部最优点，虽然当前梯度为0，但是依靠历史梯度可以越过该点继续下降； 最后，梯度噪声引起的震荡可以通过历史梯度互相抵消。 ### 3 Nesterov Momentum Nesterov Momentum由SGD+Momentum衍生而来，SGD+Momentum是将当前点的梯度和速度结合起来，而Nesterov Momentum则是将当前点的速度和下一个近似点的梯度结合起来，意味着我们不是在当前位置去看未来，而是多看了一步，在稍远一些的下一步看未来，可以提前调整步进大小： <img src="https://img-blog.csdnimg.cn/20210710192712932.png" alt="在这里插入图片描述" /> 所以Nesterov Momentum的更新规则为： <span class="math display">\[
v_{t+1}=\rho v_t-\alpha\nabla f(x_t+\rho v_t) \\
x_{t+1}=x_t+v_{t+1}
\]</span> 通常我们希望针对<span class="math inline">\(x_t\)</span>计算梯度，通过简单的变量替换，得到新的更新规则： <span class="math display">\[
v_{t+1}=\rho v_t-\alpha\nabla f(x_t) \\
x_{t+1}=x_t+v_{t+1}+\rho(v_{t+1}-v_t)
\]</span> Nesterov的实现： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">v_prev = v</span><br><span class="line">v = rho * v - lr * grads</span><br><span class="line">x += (1 + rho) * v - rho * v_prev</span><br></pre></td></tr></table></figure> ### 4 AdaGrad 前面的几种方法都是设置了一个全局的学习率，AdaGrad则通过引入二阶动量使得学习率可以针对<strong>每个参数</strong>自适应地取值：对于更新频繁的参数，已经有了很多认知，不希望因为单个样本影响太大，所以学习率可以小一些；对于更新稀疏的参数，希望从偶尔出现的能更新该参数的样本中多获得一些信息，所以学习率可以设置地大一些。为了了解参数更新的频繁程度，引入二阶动量——每个维度上历史梯度值的平方和： <span class="math display">\[
grad\_squared +=\nabla^2 f(x_t) \\
x_{t+1}=x_t-\cfrac{\alpha\nabla f(x_t)}{\sqrt{grad\_squared+10^{-7}}}
\]</span> 此时的学习率实质上是<span class="math inline">\(\cfrac{\alpha}{\sqrt{grad\_squared}}\)</span>，为了避免除0，一般分母加上一个很小的平滑项。如果某个参数更新频繁，那么grad_squared就会增大，学习率也就越小。</p>
<p>AdaGrad的实现： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grad_sq += grads**2</span><br><span class="line">x -= lr * grads / (numpy.sqrt(grad_sq) + eps)</span><br></pre></td></tr></table></figure> AdaGrad的问题在于随着grad_squared单调递增，学习率最终会单调衰减到0，意味着很可能会提早终止训练过程。 ### 5 RMSProp/AdaDelta 为了缓解AdaGrad的学习率变化过于激进的问题，二阶动量的计算不累积全部的历史梯度，只关注过去某段时间内的梯度变化，用指数移动平均值来表示过去某时间段的二阶动量的均值： <span class="math display">\[
grad\_squared=decay\_rate*grad\_squared+(1-decay\_rate)\nabla^2 f(x_t) \\
x_{t+1}=x_t-\cfrac{\alpha\nabla f(x_t)}{\sqrt{grad\_squared+10^{-7}}}
\]</span> decay_rate是一个超参数，一般取值0.9。</p>
<p>RMSProp的实现： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">grad_sq = decay * grad_sq + (1 - decay) * grads**2</span><br><span class="line">x -= lr * grads / (numpy.sqrt(grad_sq) + eps)</span><br></pre></td></tr></table></figure> 因此，RMSProp仍然是通过梯度的大小来调整每个参数的学习率，不过现在学习率不会单调递减。</p>
<h3 id="adam">6 Adam</h3>
<p>Adam的出现是集成了一阶动量思想和AdaGrad等的二阶动量思想，即Adaptive Momentum： <span class="math display">\[
m_{t+1}=\beta_1m_t+(1-\beta_1)\nabla f(x_t)\\
V_{t+1}=\beta_2V_t+(1-\beta_2)\nabla^2 f(x_t)\\
x_{t+1}=x_t-\cfrac{\alpha m_{t+1}}{\sqrt{V_{t+1}+10^{-7}}}
\]</span> 由于m和V初始化为0，所以开始的几次迭代会偏向取值0，为了弥补这一缺点，又引入了偏差纠正项，完整的Adam算法如下： <span class="math display">\[
m=\beta_1m+(1-\beta_1)\nabla f(x_t)\\
m_t=\cfrac{m}{1-\beta_1^t}\\
V=\beta_2V+(1-\beta_2)\nabla^2 f(x_t)\\
V_t=\cfrac{V}{1-\beta_2^t}\\
x_{t}=x_{t-1}-\cfrac{\alpha m_{t}}{\sqrt{V_{t}+10^{-7}}}
\]</span> Adam的实现： <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">m = beta_1 * m + (1 - beta_1) * grads</span><br><span class="line">m_t = m / (1 - beta_1**t)</span><br><span class="line">v = beta_2 * v + (1 - beta_2) * grads**2</span><br><span class="line">v_t = v / (1 - beta_2**t)</span><br><span class="line">x -= lr * m_t / (numpy.sqrt(v_t) + eps)</span><br></pre></td></tr></table></figure> 如果Adam再加上Nesterov的向后看一步的思想，就是Nadam算法。 ## Experiment 为了对上述算法有更加直观的认识，同时在部分程度上比较不同算法的性能，构造一维函数<span class="math inline">\(f(x)\)</span>作为损失函数，其表达式如下： <span class="math display">\[
f(x)=0.01x^2+sin(x)+\frac{1}{3}cos(3x)+\frac{1}{5}sin(5x)+\frac{1}{7}cos(7x)
\]</span> 这个损失函数含有大量的局部最小点以及悬崖，如图所示： <img src="https://img-blog.csdnimg.cn/2021071019313296.png" alt="在这里插入图片描述" /> 为了公平起见，比较时将x的初始值设为-29，每种算法的迭代次数均设置为300次，学习率均设置为0.1，迭代过程如下图所示： <img src="https://img-blog.csdnimg.cn/20210710193206336.png" alt="在这里插入图片描述" /> 最终的收敛结果如下表所示： | 算法 | 最终x | 最终损失 | | -------- | ------ | -------- | | SGD | -27.98 | 7.19 | | Momentum | -24.00 | 6.21 | | Nesterov | -24.00 | 6.21 | | AdaGrad | -27.98 | 7.19 | | RMSProp | -28.95 | 9.10 | | Adam | -26.46 | 5.59 |</p>
<p>从上图和上表可以看到：Adam算法在前期收敛很快，并且最终效果最好，是综合性能最佳的算法；带动量的SGD能够越过一些局部极小值，在没有精细调参的情况下一度达到了和Adam类似的效果；AdaGrad开始时的梯度很大，但是由于学习率过早地减小，最终效果并不出众；这些结果进一步佐证了之前对各种算法的分析。</p>
<p>如果将学习率设置为0.01，对比如下： <img src="https://img-blog.csdnimg.cn/20210710193256448.png" alt="在这里插入图片描述" /> 可以看到：精调后的Momentum、Nesterov和Adam的效果几乎不相上下，这只是初步调整了学习率参数，如果通过验证集更加精细地调整超参数的值，那么SGD+Momentum完全可以达到甚至超越Adam的表现，当然这也需要人为付出更多的努力，Adam这个烦恼则小得多。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">Created on Sun Apr 11 18:31:58 2021</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">@author: Jingtao Ren</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">a = tf.constant(<span class="number">3.0</span>)</span><br><span class="line">b = tf.constant(<span class="number">5.0</span>)</span><br><span class="line">c = tf.constant(<span class="number">7.0</span>)</span><br><span class="line">d = tf.constant(<span class="number">0.1</span>)</span><br><span class="line">x = tf.Variable(initial_value=-<span class="number">29.0</span>, name=<span class="string">&quot;x&quot;</span>, dtype=tf.float32)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_f</span>():</span></span><br><span class="line">    x = np.linspace(-<span class="number">30</span>, <span class="number">30</span>, <span class="number">1000</span>)</span><br><span class="line">    <span class="comment"># y = -20.0 * np.exp(b * np.abs(x)) - np.exp(np.cos(c * x)) + 20.0 + np.exp(1)</span></span><br><span class="line">    y = (<span class="number">0.1</span> * x) ** <span class="number">2</span> + np.sin(x) + np.cos(a * x) / a + np.sin(b * x) / b + np.cos(c * x) / c</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;x&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;y&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Loss Function&#x27;</span>)</span><br><span class="line">    plt.plot(x, y)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plot_train</span>(<span class="params">y</span>):</span></span><br><span class="line">    x = np.arange(<span class="number">300</span>)</span><br><span class="line">    labels = [<span class="string">&#x27;SGD&#x27;</span>, <span class="string">&#x27;Momentum&#x27;</span>, <span class="string">&#x27;Nesterov&#x27;</span>, <span class="string">&#x27;AdaGrad&#x27;</span>, <span class="string">&#x27;RMSProp&#x27;</span>, <span class="string">&#x27;Adam&#x27;</span>]</span><br><span class="line">    plt.figure()</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;Iteration&#x27;</span>)</span><br><span class="line">    plt.ylabel(<span class="string">&#x27;Loss&#x27;</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;Algorithm Comparison&#x27;</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):    </span><br><span class="line">        plt.plot(x, y[i], label=labels[i])</span><br><span class="line">        plt.legend()</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loss</span>():</span></span><br><span class="line">    <span class="comment"># y = a * tf.exp(b * tf.abs(x)) - tf.exp(tf.cos(c * x)) - a + tf.exp(tf.constant(1.0))</span></span><br><span class="line">    y = tf.<span class="built_in">pow</span>(d * x, <span class="number">2</span>) + tf.sin(x) + tf.cos(a * x) / a + tf.sin(b * x) / b + tf.cos(c * x) / c</span><br><span class="line">    <span class="keyword">return</span> (y)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">minimize</span>(<span class="params">optimizer, iters = <span class="number">300</span></span>):</span></span><br><span class="line">    y = []</span><br><span class="line">    <span class="comment"># optimizer = tf.keras.optimizers.SGD(learning_rate=0.1)</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> tf.<span class="built_in">range</span>(iters):</span><br><span class="line">        optimizer.minimize(loss, [x])</span><br><span class="line">        y.append(loss())</span><br><span class="line">    tf.<span class="built_in">print</span>(<span class="string">&quot;Final x = &quot;</span>, x)</span><br><span class="line">    tf.<span class="built_in">print</span>(<span class="string">&quot;Final Loss = &quot;</span>, loss())</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&quot;__main__&quot;</span>:</span><br><span class="line">    <span class="comment"># plot_f()</span></span><br><span class="line">    ops = [tf.keras.optimizers.SGD(learning_rate=<span class="number">0.1</span>), tf.keras.optimizers.SGD(learning_rate=<span class="number">0.1</span>, momentum=<span class="number">0.9</span>),</span><br><span class="line">           tf.keras.optimizers.SGD(learning_rate=<span class="number">0.1</span>, momentum=<span class="number">0.9</span>, nesterov=<span class="literal">True</span>), tf.keras.optimizers.Adagrad(learning_rate=<span class="number">0.1</span>),</span><br><span class="line">           tf.keras.optimizers.Adadelta(learning_rate=<span class="number">0.1</span>, rho=<span class="number">0.9</span>), tf.keras.optimizers.Adam(learning_rate=<span class="number">0.1</span>)]</span><br><span class="line">    y = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">6</span>):</span><br><span class="line">        x.assign(-<span class="number">29.0</span>)</span><br><span class="line">        y.append(minimize(ops[i]))</span><br><span class="line">    plot_train(y)</span><br></pre></td></tr></table></figure>
<p>当然，这个实验非常简单，损失函数形式是一维的，实际中的网络模型参数的数量可能达到百万级别，超高维情况下算法的效率、鲁棒性以及模型最终的泛化能力才是我们真正关心的。</p>
<p>最后贴2张神图总结下： <img src="https://img-blog.csdnimg.cn/20210306203509952.gif#pic_center" alt="在这里插入图片描述" /><img src="https://img-blog.csdnimg.cn/2021030620351970.gif#pic_center" alt="在这里插入图片描述" /> ## Research Adam虽然是集大成者，而且也被推荐为起始的默认优化算法，但是一些Paper揭示了Adam的一些问题。 ### 1 过拟合 Berkeley在NIPS 2017的一篇文章指出：如果一个问题有多个全局极优，即使从相同的初始值出发，不同的优化算法也会得到完全不同的结果。文章构造了一个简单的线性可分的二分类问题，证明了SGD在这种情况下测试误差为0，而AdaGrad等自适应方法会把所有的测试样例分为正类，泛化能力极差，也就是根本不能工作。</p>
<p>随后作者又用VGG+BN+Dropout的网络结构在CIFAR-10数据集上进行了实验： <img src="https://img-blog.csdnimg.cn/20210710193712619.png" alt="在这里插入图片描述" /> 可以看到：前期训练中Adam有优势，但SGD的泛化能力确实比Adam要好。</p>
<p>最后，为了彻底黑化Adam，文章又用了文本数据集和一些NLP模型做了实验： <img src="https://img-blog.csdnimg.cn/20210710193823396.png" alt="在这里插入图片描述" /> 即便有时候自适应方法的训练loss会更低，但SGD的泛化能力都无一例外地胜过了自适应的方法。自适应方法在训练初期速度很快，但是后期表现平平。</p>
<p>泛化能力差的原因在于：自适应方法倾向于关注稀疏的特征，因为这些特征对于训练样例的鉴别是很有效的，尤其在训练样例数少而特征较多的数据集中，但是这些特征其实并非关键特征，这样自适应学习率算法出现过拟合的风险就会增大，导致泛化能力不佳，最终的收敛效果不如传统的SGD。 ### 2 二阶动量波动 Google的一篇文章从数学上证明了在某些特定情况下Adam可能不收敛，因为二阶动量取的是某个时间窗口的变化，所以<span class="math inline">\(V_t\)</span>的变化可能会剧烈震荡，尤其在高维情况下，梯度的方差可能随时间波动很大，导致学习率震荡，模型无法收敛。这也是为什么一般<span class="math inline">\(\beta_2\)</span>要取0.999这么大的值，避免二阶动量有太大波动。</p>
<p>一般认为Adam默认的<span class="math inline">\(\beta_1\)</span>和<span class="math inline">\(\beta_2\)</span>不需要调整，采用默认的0.9和0.999即可。但是这两个超参如果不按这样设置，Adam可能永远不会收敛到最优值。文章从数学上证明了对任意的<span class="math inline">\(\beta_1,\beta_2\in[0,1),\beta_1&lt;\sqrt{\beta_2}\)</span>，都存在一个随机的凸优化问题使得Adam不能收敛到最优解。</p>
<p>为了避免二阶动量的剧烈震荡，文章对其进行了控制，提出了一个新算法AMSGrad确保模型收敛，<span class="math inline">\(V_t=max(V_{t-1},\beta_2V_{t-1}+(1-\beta_2)\nabla^2 f(x_t))\)</span>。</p>
<p>作者随后通过人造数据和真实数据进行了实验：</p>
<p>人造数据上的结果： <img src="https://img-blog.csdnimg.cn/20210710193934596.png" alt="在这里插入图片描述" /> 很显然在Adam没有找到最优解的这些数据上，改进后的算法都表现良好。</p>
<p>在MNIST上的效果： <img src="https://img-blog.csdnimg.cn/20210710193956571.png" alt="在这里插入图片描述" /> 这篇文章最终获得了2018年ICLR最佳论文，但是引起了很大争议。主要原因在于其构造的令Adam失效的数据在实际情况中出现的概率极低，即使出现也会在数据预处理时被筛掉，因此并没有特别广泛的实际用处。另外，文章过于强调训练集上的损失函数值，甚至有人通过复现表明文章提出的AMSGrad算法在测试数据上表现很差，与原文中的某些结论相互矛盾。 ### 3 学习率下降 arXiv上的一篇文章通过在CIFAR-10上的实验证明Adam在一些情况下虽然速度快，但收敛效果没有SGD好： <img src="https://img-blog.csdnimg.cn/20210710194231292.png" alt="在这里插入图片描述" /> 文章通过实验发现主要原因在于后期Adam的学习率过低，影响了最终效果。文章尝试通过控制学习率下界，提高了最终收敛效果。</p>
<p>既然Adam后期有问题，那么一个自然的改进就是前期训练使用Adam，用来快速减小loss；后期训练转换为SGD，用稍慢的速度寻找更佳的解甚至是最优解。但是这样也会引入新的问题：在什么时刻切换？切换为SGD后的学习率又该如何设置？</p>
<p>文章提出了SWATS(Switches from Adam to SGD)策略来解决上面2个问题，在CIFAR-10和CIFAR-100数据集上实验效果看着还不错： <img src="https://img-blog.csdnimg.cn/20210710194309531.png" alt="在这里插入图片描述" /> <img src="https://img-blog.csdnimg.cn/20210710194329636.png" alt="在这里插入图片描述" />这些文章都采用了一些比较极端的数据去探索Adam的不适情况，然而实际中遇到这些极端情况的概率并不大，因此Adam并不失为首选尝试。通过上面的讨论可以看到：SGD和Adam各有优劣，精调后的SGD一般最终会收敛到更好的效果；Adam在训练前期收敛速度快，在稀疏数据上表现更好，对超参不敏感，不需要十分精细的调参。</p>
<p>如果对优化算法不熟悉，可以先尝试SGD+Nesterov Momentum或者Adam；如果对某个优化算法很精通，那么调参就会相对容易些。如果资源足够，也可以尝试L-BFGS等二阶优化方法。另外，选择之前要充分了解数据的性质，对于比较稀疏的数据可以优先尝试学习率自适应调整的算法。 ## Reference [1] CS231n: Convolutional Neural Networks for Visual Recognition. lecture 8, Stanford University. [2] The Marginal Value of Adaptive Gradient Methods in Machine Learning. NIPS'17 [3] On the Convergence of Adam and Beyond. ICLR'18 [4] Improving Generalization Performance by Switching from Adam to SGD. arXiv [5] Optimization methods for large-scale machine learning. SIAM Review, 2018. [6] Optimization for deep learning: theory and algorithms. arXiv, 2019. [7] Understanding Black-box Predictions via Influence Functions. ICML'17. [8] Understanding Deep Learning Requires Rethinking Generalization. ICLR'17.</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://eimadrigal.github.io/2021/06/17/Gradient%20Boosting/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/favicon.png">
      <meta itemprop="name" content="EIMadrigal">
      <meta itemprop="description" content="Hello World">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EI Madrigal's Space">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/2021/06/17/Gradient%20Boosting/" class="post-title-link" itemprop="url">Gradient Boosting</a>
        </h2>

        <div class="post-meta">

		  
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2021-06-17 08:51:00" itemprop="dateCreated datePublished" datetime="2021-06-17T08:51:00+08:00">2021-06-17</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="gradient-boosting-regression">Gradient Boosting Regression</h2>
<h2 id="gradient-boosting-classification">Gradient Boosting Classification</h2>
<h2 id="xgboost">XGBoost</h2>
<h2 id="决策树集成">决策树集成</h2>
<p>集成学习可以组合多个基学习器，产生更加优异的性能。将决策树（如CART）作为基学习器，结合每个基学习器的预测结果作为最终输出，就像<a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html">下图</a>这样： <img src="https://img-blog.csdnimg.cn/2021061621501811.png" alt="在这里插入图片描述" /> 正式一些的表示： <span class="math display">\[\hat{y}_i = \sum_{k=1}^K f_k(x_i), f_k \in \mathcal{F}\]</span> 其中，<span class="math inline">\(K\)</span>是决策树个数，<span class="math inline">\(f_k(x_i)\)</span>表示第<span class="math inline">\(k\)</span>个决策树的预测值。</p>
<p>为了定量描述模型参数与训练数据的匹配程度，我们还要定义待优化的目标函数： <span class="math display">\[\text{obj}(\theta) = \sum_i^n l(y_i, \hat{y}_i) + \sum_{k=1}^K \Omega(f_k)\]</span> ## Boosting Decision Tree 集成多棵树的方式可以是Bagging，也可以是Boosting。Boosting的motivation是用一棵新树不断拟合当前的集成模型与真实值的残差，拟合后将该树也加入模型中，即所谓的Additive Training： <span class="math display">\[\hat{y}_i^{(0)} = 0\\
\hat{y}_i^{(1)} = f_1(x_i) = \hat{y}_i^{(0)} + f_1(x_i)\\
\hat{y}_i^{(2)} = f_1(x_i) + f_2(x_i)= \hat{y}_i^{(1)} + f_2(x_i)\\
\dots\\
\hat{y}_i^{(t)} = \sum_{k=1}^t f_k(x_i)= \hat{y}_i^{(t-1)} + f_t(x_i)\]</span> 好了，接下来的问题就是每次迭代时的那棵新树<span class="math inline">\(f_t\)</span>要怎么训练呢？一个直观的想法就是选择那棵令目标函数最小的树： <span class="math display">\[\text{obj}^{(t)} = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t)}) + \sum_{i=1}^t\Omega(f_i) \\
          = \sum_{i=1}^n l(y_i, \hat{y}_i^{(t-1)} + f_t(x_i)) + \Omega(f_t) + \mathrm{constant}\]</span> 我们先选择MSE作为损失函数，看看会发生什么： <span class="math display">\[{obj}^{(t)} = \sum_{i=1}^n (y_i - (\hat{y}_i^{(t-1)} + f_t(x_i)))^2 + \sum_{i=1}^t\Omega(f_i) \\
          = \sum_{i=1}^n [2(\hat{y}_i^{(t-1)} - y_i)f_t(x_i) + f_t(x_i)^2] + \Omega(f_t) + \mathrm{constant}\]</span> 虽然MSE的形式比较友好，但是如果选择其它损失函数就很难有上式那般人性了，吃得太饱的同学可以试试logistic loss： <span class="math display">\[L(\theta) = \sum_i[ y_i\ln (1+e^{-\hat{y}_i}) + (1-y_i)\ln (1+e^{\hat{y}_i})]\]</span> 为了增强可扩展性、便于计算，一般采用损失函数的二阶泰勒展开去做一个近似： <span class="math display">\[\text{obj}^{(t)} = \sum_{i=1}^n [l(y_i, \hat{y}_i^{(t-1)}) + g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t) + \mathrm{constant}\]</span> 其中，<span class="math inline">\(g_i = \partial_{\hat{y}_i^{(t-1)}} l(y_i, \hat{y}_i^{(t-1)}),h_i = \partial_{\hat{y}_i^{(t-1)}}^2 l(y_i, \hat{y}_i^{(t-1)})\)</span>。 扔掉所有常数项，就得到了第<span class="math inline">\(t\)</span>步的目标函数： <span class="math display">\[\sum_{i=1}^n [g_i f_t(x_i) + \frac{1}{2} h_i f_t^2(x_i)] + \Omega(f_t)\]</span></p>
<p>弄完了training loss，接着还得研究下正则项<span class="math inline">\(\Omega(f_t)\)</span>，首先得给<span class="math inline">\(f(x)\)</span>来一个正式点的定义： <span class="math display">\[f_t(x) = w_{q(x)}, w \in R^T, q:R^d\rightarrow \{1,2,\cdots,T\} .\]</span> 其中，<span class="math inline">\(w\)</span>是叶子结点的得分向量，<span class="math inline">\(q\)</span>是将样本点映射到对应叶子的函数，<span class="math inline">\(T\)</span>是叶子数目。 如果有点抽象，就看看上图中的左子图吧：<span class="math inline">\(w=[2,-1],f(男孩)=w_{q(男孩)}=w_0=2\)</span>。</p>
<p>模型复杂度的具体定义随你了，XGBoost是这么定义的： <span class="math display">\[\Omega(f) = \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2\]</span> 就用上式重新写出我们第<span class="math inline">\(t\)</span>步的目标函数： <span class="math display">\[\text{obj}^{(t)} \approx \sum_{i=1}^n [g_i w_{q(x_i)} + \frac{1}{2} h_i w_{q(x_i)}^2] + \gamma T + \frac{1}{2}\lambda \sum_{j=1}^T w_j^2\\
= \sum^T_{j=1} [(\sum_{i\in I_j} g_i) w_j + \frac{1}{2} (\sum_{i\in I_j} h_i + \lambda) w_j^2 ] + \gamma T\]</span> 其中，<span class="math inline">\(I_j = \{i|q(x_i)=j\}\)</span>表示第<span class="math inline">\(j\)</span>个叶子中样本点的索引集合，由于任意一个叶子中样本点得分相同，因此上式写成了对<span class="math inline">\(T\)</span>个叶子的求和。</p>
<p>令<span class="math inline">\(G_j = \sum_{i\in I_j} g_i\)</span>及<span class="math inline">\(H_j = \sum_{i\in I_j} h_i\)</span>，就有了一个相对简洁的表示： <span class="math display">\[\text{obj}^{(t)} = \sum^T_{j=1} [G_jw_j + \frac{1}{2} (H_j+\lambda) w_j^2] +\gamma T\]</span> 因为叶子之间相互独立，所以令目标函数最优的得分向量<span class="math inline">\(w\)</span>为： <span class="math display">\[w_j^\ast = -\frac{G_j}{H_j+\lambda}\\
\text{obj}^\ast = -\frac{1}{2} \sum_{j=1}^T \frac{G_j^2}{H_j+\lambda} + \gamma T\]</span> 目标函数<span class="math inline">\(obj^*\)</span>的值衡量着本次迭代树结构<span class="math inline">\(q(x)\)</span>对训练数据的拟合程度。</p>
<p>云里雾里一大堆，我都烦了，来看个例子： <img src="https://img-blog.csdnimg.cn/2021061716123725.png" alt="在这里插入图片描述" /> 假设在第<span class="math inline">\(t\)</span>次迭代选了这么一棵树，按照if-then规则将训练样本分到相应的叶子，将梯度信息相加得到每个叶子对应的<span class="math inline">\(G,H\)</span>，接着用<span class="math inline">\(obj^*\)</span>计算这棵树最小的损失，不行就换一种树结构，以求减小<span class="math inline">\(obj^*\)</span>。</p>
<p>忙活了大半天，终于知道了怎么度量一棵树的好坏。那么只要枚举所有可能的树结构，选那个令<span class="math inline">\(obj^*\)</span>最小的就好了。傻子都知道这是不行滴，所以只能贪心地一层一层地剥开你的心...哦不对，一层一层地优化：将结点分类为左孩子和右孩子的得分增益为： <span class="math display">\[Gain = \frac{1}{2} \left[\frac{G_L^2}{H_L+\lambda}+\frac{G_R^2}{H_R+\lambda}-\frac{(G_L+G_R)^2}{H_L+H_R+\lambda}\right] - \gamma\]</span> 其中，第一/二项分别表示左/右孩子的分数，第三项表示原始节点的分数，最后一项表示增加叶子的惩罚。可以看到：如果分裂后的得分增益小于<span class="math inline">\(\gamma\)</span>，就不要继续分了，凑合过吧...</p>
<p>为了在每层获取到最佳的分裂点，通常先将训练数据排个序： <img src="https://img-blog.csdnimg.cn/20210617164041605.png" alt="在这里插入图片描述" /> 暴力枚举一遍分裂点找最优就可以啦！</p>
<ul>
<li><span class="math inline">\(f_0(x)=0\)</span></li>
<li>对于第m棵树的训练：
<ul>
<li>首先计算每条训练数据的残差：<span class="math inline">\(r_{mi}=y_i-f_{m-1}(x_i),i=1,2...,N\)</span></li>
<li>接着通过拟合上面得到的残差数据，训练出回归树<span class="math inline">\(T_m(x)\)</span></li>
<li>此时第m棵树的输出即为<span class="math inline">\(f_m(x)=f_{m-1}(x)+T_m(x)\)</span></li>
</ul></li>
<li>进行M次训练后得到最终的模型</li>
</ul>
<p>可以看到：Boosting Decision Tree每次迭代都将上一轮预测结果的残差作为当前的训练集，对于平方损失容易求得损失函数最小值的点，但是对于稍复杂的损失函数，残差的获得就只能通过负梯度<span class="math inline">\(\frac{\partial L(y_i,f(x_i))}{f(x_i)}\)</span>去逼近，这就是GBDT的核心思想。 GBDT的训练与Boosting Decision Tree很相似：</p>
<ul>
<li>初始化弱学习器<span class="math inline">\(f_0(x)=\underset{c}{arg\ min}\sum_{i=1}^{N}L(y_i,c)\)</span>，如果损失函数是MSE，那么<span class="math inline">\(f_0(x)=\frac{1}{N}\sum_{i=1}^{N}y_i\)</span></li>
<li>对于第m棵树的训练：
<ul>
<li>计算负梯度：<span class="math inline">\(r_{mi}=-\frac{\partial L(y_i,f(x_i))}{\partial f(x_i)},f(x)=f_{m-1}(x)\)</span></li>
<li>得到新的训练集<span class="math inline">\((x_i,r_{mi})\)</span>，训练产生一棵新的回归树，对应的叶子结点域为<span class="math inline">\(R_{mj},j=1,...,J\)</span>，<span class="math inline">\(J\)</span>为叶子结点个数</li>
<li>对第j个叶子结点，计算最佳拟合值：<span class="math inline">\(c_{mj}=\underset{c}{arg\ min}\sum_{x_i\in R_{mj}}L(y_i,f_{m-1}(x_i)+c)\)</span></li>
<li>更新强学习器：<span class="math inline">\(f_m(x)=f_{m-1}(x)+\sum_{i=1}^{J}c_{mj}I(x\in R_{mj})\)</span></li>
</ul></li>
<li>最终的学习器为：<span class="math inline">\(\hat f(x)=f_M(x)=f_0(x)+\sum_{m=1}^{M}\sum_{j=1}^{J}c_{mj}I(x\in R_{mj})\)</span></li>
</ul>
<h2 id="implementation">Implementation</h2>
<h2 id="properties">Properties</h2>
<ol type="1">
<li>extrapolate问题 众所周知随机森林回归是不具备推理能力的，那么XGBoost可以吗？ 答案是可以，因为梯度提升模型并不直接根据训练集的结果做预测，而是通过一系列树的加和得到，加和结果取决于每棵树的权重，权重则是由损失函数的一二阶梯度优化得来，并不依赖于训练集的上下限。</li>
<li>缺失值问题 GBDT/GBRT自身不支持缺失值的自动填充，例如使用sklearn中的GradientBoostingRegressor在训练数据包含缺失值时将无法训练，人工填充可能会引入偏差，但是XGBoost却可以自动地处理缺失值（但并不是填充）。 根据陈天奇大佬的说法： &gt; Internally, XGBoost will automatically learn what is the best direction to go when a value is missing. Equivalently, this can be viewed as automatically "learn" what is the best imputation value for missing values based on reduction on training loss.</li>
</ol>
<p>那么究竟是如何自动学习最佳的分裂方向呢？ 假设在结点A有50条训练样本，并且该结点只有一个可能的分割点：比如只有一个二元特征x，那么分割点就只有该特征取值为0或1，这样训练数据可以被分为3组： 1. x取值为B的20条样例 2. x取值为C的20条样例 3. x缺失的10条样例，叫做M组</p>
<p>那么M组的样例会被分别赋到B和C，接着计算<span class="math inline">\(\{(B,M),C\}\)</span>和<span class="math inline">\(\{B,(C,M)\}\)</span>的得分及损失函数衰减，两者中选择损失函数衰减大的。 如果使用MSE作为损失函数，并且B的标签均值为5，C的标签均值为10，M的标签均值为0。 如果使用<span class="math inline">\(\{(B,M),C\}\)</span>：<span class="math inline">\(\frac{|M|}{|B| + |M|}\text{mean}(M) + \frac{|B|}{|M|+|B|}\text{mean}(B) = \frac{10}{30}0 + \frac{20}{30}5 = 3.\overline{3}\)</span> 如果使用<span class="math inline">\(\{B,(C,M)\}\)</span>：<span class="math inline">\(\frac{|M|}{|C| + |M|}\text{mean}(M) + \frac{|C|}{|M|+|C|}\text{mean}(C) = \frac{10}{30}0 + \frac{20}{30}10 = 6.\overline{3}\)</span> 最后计算两者的MSE与划分前MSE的差，选择使得MSE下降更快的作为分裂方向（也就是得分gain更大的方向）。</p>
<p>在寻找最优特征分裂点（如年龄＜20还是年龄＜30）时，只访问该特征不含缺失值的训练样例，即如果年龄缺失，就不参与20和30的决策，这样计算复杂度也就降低了，尤其是对于稀疏数据。</p>
<p>预测时的缺失值有２种情况： 1.　训练阶段已经见识过该缺失值了：按照训练时选定的方向往下走就行 2.　训练阶段该特征没有缺失：默认走向右子树。</p>
<p>Ref里还有一个更加全面的例子，训练集有6个小孩，只有一个特征年龄（其中有2个样例年龄缺失），标签是身高，初始预测值为0.5，接下来每棵树都要拟合残差。 | Age | Height | Res | | ------------ | ------------ | ------------ | | 7 | 130 | －129.5 | | 9 | 148 | －147.5 | | 6 | 115 | －114.5 | | 15 | 164 | －163.5 | | ？ | 125 | －124.5 | | ？ | 140 | －139.5 |</p>
<p>接着要根据年龄特征寻找最优的分裂点，将年龄排序并选择中点（<strong>注意：这里就不考虑缺失值样例了</strong>），因此候选分裂点有6.5，8，12，对于每个候选点，分别计算将缺失样例划到左子树和右子树的Quality/Similarity Score：</p>
<p><span class="math display">\[
Quality\ Score=\frac{(\sum residuals)^2}{\#residuals + \lambda}
\]</span></p>
<p>比如，对于分裂点6.5： 如果划到左子树：<span class="math inline">\(Gain＝划分后的Quality\ Score－划分前的Quality\ Score＝\frac{(-114.5-124.5-139.5)^2}{3} + \frac{(-129.5-147.5-163.5)^2}{3} - \frac{(-129.5-147.5-114.5-163.5-124.5-139.5)^2}{6}=640.7\)</span> 如果划到右子树：<span class="math inline">\(Gain＝划分后的Quality\ Score－划分前的Quality\ Score＝580.8\)</span></p>
<p>接着对于8：1083；630.8 对于12：874.8；216 从中选择gain最大的（也就是使得损失函数最小的），分裂点选8，缺失值划到左子树。 ## Bug <a target="_blank" rel="noopener" href="https://www.lycecho.com/archives/2364">PYTHON XGBOOST 报错 KEYERROR: ‘BASE_SCORE’</a></p>
<h2 id="references">References</h2>
<p><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=3CC4N4z3GJc"><strong>Gradient Boost</strong></a> <a target="_blank" rel="noopener" href="https://xgboost.readthedocs.io/en/latest/tutorials/model.html">Introduction to Boosted Trees</a> <a target="_blank" rel="noopener" href="https://datascience.stackexchange.com/questions/15305/how-does-xgboost-learn-what-are-the-inputs-for-missing-values">Missing values in XGBoost</a> <a target="_blank" rel="noopener" href="https://stats.stackexchange.com/questions/304962/is-is-possible-for-a-gradient-boosting-regression-to-predict-values-outside-of-t">Is is possible for a gradient boosting regression to predict values outside of the range seen in its training data?</a> <a target="_blank" rel="noopener" href="https://datascience.stackexchange.com/questions/77234/can-boosted-trees-predict-below-the-minimum-value-of-the-training-label">Can Boosted Trees predict below the minimum value of the training label?</a> <a target="_blank" rel="noopener" href="https://github.com/dmlc/xgboost/issues/1581#issuecomment-249853718">Why does XGBoost regression predict completely unseen values?</a> <a target="_blank" rel="noopener" href="https://medium.com/hypatai/how-xgboost-handles-sparsities-arising-from-of-missing-data-with-an-example-90ce8e4ba9ca">How XGBoost Handles Sparsities Arising From of Missing Data? (With an Example)</a> <a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=OtD8wVaFm6E"><strong>XGBoost Regression</strong></a></p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left" aria-label="Previous page"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span><a class="page-number" href="/page/3/">3</a><span class="space">&hellip;</span><a class="page-number" href="/page/17/">17</a><a class="extend next" rel="next" href="/page/3/"><i class="fa fa-angle-right" aria-label="Next page"></i></a>
  </nav>



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="EIMadrigal"
      src="/images/favicon.png">
  <p class="site-author-name" itemprop="name">EIMadrigal</p>
  <div class="site-description" itemprop="description">Hello World</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">167</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/EIMadrigal" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;EIMadrigal" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:andrew.renj@gmail.com" title="E-Mail → mailto:andrew.renj@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://www.cnblogs.com/EIMadrigal" title="cnblogs → https:&#x2F;&#x2F;www.cnblogs.com&#x2F;EIMadrigal" rel="noopener" target="_blank"><i class="fab fa-codiepie fa-fw"></i>cnblogs</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://weibo.com/EIMadrigal" title="Weibo → https:&#x2F;&#x2F;weibo.com&#x2F;EIMadrigal" rel="noopener" target="_blank"><i class="fab fa-weibo fa-fw"></i>Weibo</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2018-02 – 
  <span itemprop="copyrightYear">2022</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">EIMadrigal</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>


    <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

    <span id="busuanzi_container_site_pv">Total views: <span id="busuanzi_value_site_pv"></span></span>
    <span class="post-meta-divider">|</span>
    <span id="busuanzi_container_site_uv">Total visitors: <span id="busuanzi_value_site_uv"></span></span>
    <span class="post-meta-divider">|</span>

<script>
$(document).ready(function() {

    var int = setInterval(fixCount, 50);
    var countOffset = 20000;

    function fixCount() {            
       if (document.getElementById("busuanzi_container_site_pv").style.display != "none")
        {
            $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + countOffset); 
            clearInterval(int);
        }                  
        if ($("#busuanzi_container_site_pv").css("display") != "none")
        {
            $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + countOffset);
            clearInterval(int);
        }  
    }
       	
});
</script> 

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  
      

<script>
  if (typeof MathJax === 'undefined') {
    window.MathJax = {
      loader: {
        source: {
          '[tex]/amsCd': '[tex]/amscd',
          '[tex]/AMScd': '[tex]/amscd'
        }
      },
      tex: {
        inlineMath: {'[+]': [['$', '$']]},
        tags: 'ams'
      },
      options: {
        renderActions: {
          findScript: [10, doc => {
            document.querySelectorAll('script[type^="math/tex"]').forEach(node => {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            });
          }, '', false],
          insertedScript: [200, () => {
            document.querySelectorAll('mjx-container').forEach(node => {
              let target = node.parentNode;
              if (target.nodeName.toLowerCase() === 'li') {
                target.parentNode.classList.add('has-jax');
              }
            });
          }, '', false]
        }
      }
    };
    (function () {
      var script = document.createElement('script');
      script.src = '//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
      script.defer = true;
      document.head.appendChild(script);
    })();
  } else {
    MathJax.startup.document.state(0);
    MathJax.texReset();
    MathJax.typeset();
  }
</script>

    

  


</body>
</html>
